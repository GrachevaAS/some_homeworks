{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании вам может помочь питон-бук по RNN из вашего основного курса : https://github.com/ml-mipt/ml-mipt/blob/master/week12_seq2seq_and_embeddings/rnn_pytorch.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом домашнем задании мы будем генерировать тексты из высказываний Ницше при помощи рекуррентных сетей. \n",
    "Наша модель будет основываться на символах и генерировать посимвольно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем данные. Корпус состоит из высказываний Ницше, разделеных переносом строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем данные. Мы будем работать с символами. Посмотрим сколько уникальных символов есть в корпусе.\n",
    "Также поставим каждому символу в соответствие число, чтобы далее работать с числами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "with io.open('nietzsche.txt', encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте датасет. Мы будем по maxlen предыдущих символов предсказывать один следующий символ, таким образом решаем задачу классификации на `len(chars)` классов. Датасет должен состоять из пар вида [maxlen символов]-[следующий символ]. <br>\n",
    "\n",
    "Для этого есть несколько вариантов: <br>\n",
    "\n",
    "1) Разбить весь текст на высказывания. Внутри каждого высказывания пройтись окошком размера maxlen символов и взять следующий после окошка символ как ответ. Проходиться по высказыванию можно с некоторым шагом step, то есть сдвиг окошек взять равным step. В данном случае придется завести специальный символ для паддинга (например, #), которого нет в словаре. Этот символ будет использоваться для увеличения размера высказываний. Например, предложение *\"I like NLP\"* превратится в *\"###I like NLP###\"*. Сколько таких символов добавлять - гиперпараметр.\n",
    "Не забудьте добавить новый символ в словарь и поставить ему в соответствие число.<br>\n",
    "\n",
    "2) Не разбивать на высказывания, а работать с полным текстом. По нему аналогично пройтись окошками и составить датасет. В таком случае одно окно может содержать конец одного высказывания и начало другого (разделенных \\n), но зато не нужно делать padding.\n",
    "\n",
    "`prev_chars` - массив из предыдущих maxlen символов.  <br>\n",
    "`next_chars` - массив из следующего символа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "count of elements in dataset: 241687\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40 # you can change this number\n",
    "step = 2 # you can change this number\n",
    "\n",
    "PAD = '#'\n",
    "chars = sorted(list(set(text)) + [PAD])\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "current_phrase = ''\n",
    "phrases = []\n",
    "for s in text:\n",
    "    current_phrase += s\n",
    "    if s in ['.', '!', '?']:\n",
    "        if len(current_phrase) != 0:\n",
    "            phrases.append(PAD * step + current_phrase.strip() + PAD * step)\n",
    "        current_phrase = ''    \n",
    "\n",
    "prev_chars = []\n",
    "next_char = []\n",
    "\n",
    "for p in phrases:\n",
    "    for i in range(0, len(p) - maxlen - 1, step):\n",
    "        prev_chars.append(p[i:i + maxlen])\n",
    "        next_char.append(p[i + maxlen])\n",
    "\n",
    "print('count of elements in dataset:', len(prev_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно полученный датасет перевести из текстового формата в векторный.\n",
    "Тут тоже есть несколько вариантов: <br>\n",
    "\n",
    "1) Перевести каждый символ в число и каждому числу поставить в соответствие one-hot вектор. В таком случае prev_chars превратиться в массив размера (count_elements, maxlen, len(chars)). \n",
    "next_char лучше не переводить в one-hot, а оставить в численном формате. Это связано с тем, что PyTorch при подсчете лосса принимает в аргументах метки в виде чисел, а не one-hot векторов. То есть next_char должен иметь размер (count_elements,)<br>\n",
    "\n",
    "2) Перевести каждый символ в число. Тогда prev_chars превратиться в массив размера (count_elements, maxlen). next_char здесь обрабатывается так же как и в пункте 1). После этого внутри модели будем строить обучаемые эмбеддинги с помощью специального слоя (об этом далее), чтобы перевести эти числа в вектора (не пугайтесть, это не сложно). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[char_indices[c] for c in p] for p in prev_chars])\n",
    "y = np.array([char_indices[c] for c in next_char])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем полученные данные на обучение и валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим к написанию модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель будет состоять из одного или нескольких RNN. На вход модель принимает предыдущие maxlen символов и на выходе возвращает вероятности быть следующим символом для каждого символа из словаря. <br>\n",
    "Заметим, что если ранее вы кодировали символы one-hot векторами, то эти one-hot вектора уже можно подавать на вход рекуррентной сети. Если же вы кодировали каждый символ числом, то такое подавать на вход RNN плохо (вы задали порядок на символах). Чтобы избежать этой проблемы используется обучаемый эмбеддинг слой (`nn.Embedding`), который каждому числу сопоставит некоторое обучаемое векторное представление.  <br>\n",
    "\n",
    "*Напоминание из лекции про* ***Embedding слой***: <br>\n",
    "Пусть у нас есть vocab_len токенов в словаре и каждому токену мы хотим поставить в соответствие вектор-представление размера emb_size. Тогда заведем обучаемую матрицу W размера (vocab_len, emb_size). i-ая строка такой матрицы как раз и является эмбеддингом токена под индексом i. Таким образом, Embedding слой принимает на вход индекс токена из словаря и просто берет строку из матрицы W с таким индексом. <br>\n",
    "Остается понять, почему такое преобразование не испортит подсчет градиентов. Для этого нужно понять, что Embedding слой эквивалентен следующему : возьмем на вход индекс токена, переведем этот индекс в one-hot вектор и умножем полученный вектор на матрицу W. Немного подумав, можно понять, что это то же самое, что и просто взятие определенной строки из матрицы W. То есть Embedding слой эквивалентен обычному полносвязному слою без смещения, поэтому такое преобразование является дифференцируемым.<br><br>\n",
    "\n",
    "После того, как получены векторные представления для каждого символа, их можно подать на вход рекуррентной сети. \n",
    "Для этого вам могут понадобиться следующие слои: `nn.RNN`, `nn.GRU`, `nn.LSTM`. Каждый из этих слоев в конструкторе принимает 3 важных параметра : `input_size`, `hidden_size`, `num_layers`. <br>\n",
    "`input_size` - размерность входного эмбеддинга для токена (vocab_len в случае использования one-hot векторов и emb_size в случае использования Embedding слоя). <br>\n",
    "`hidden_size` - размерность скрытого состояния $h$.<br>\n",
    "`num_layers` - количество таких rnn-ок, настаканных друг на друга. Например, num_layers = 2 означает, что первая rnn принимает на вход эмбеддинги символов и на каждом этапе возвращает скрытое состояние, а вторая rnn принимает на вход скрытые состояния первой rnn и возвращает свои скрытые состояния. Не берите num_layers слишком большой, 1-3 достаточно.<br>\n",
    "\n",
    "Метод forward у данных слоев принимает всю входную последовательность размера (maxlen, batch_size, emb_size) для всех элементов в батче и применяет рекуррентную ячейку последовательно сначала к первым символам, потом ко вторым и так далее. Кроме того, метод принимает начальную инициализацию для скрытого состояния. Для `nn.RNN` и `nn.GRU` начальная инициализация - один вектор размера (num_layers, batch_size, hidden_size), а для `nn.LSTM` 2 вектора размера (num_layers, batch_size, hidden_size) так как LSTM имеет 2 состояния. Обычно в качестве начальной инициализации берут нулевой тензор. Возвращает данный метод всю последовательность hidden_state-ов на каждом этапе времени и hidden_state в последний этап времени (у LSTM еще и cell_state в последний этап времени).<br>\n",
    "Заметим еще раз, входная последовательность должна иметь размер (maxlen, batch_size, emb_size), поэтому вам скорей всего нужно будет сделать `.traspose(0, 1)`, что поменяет местами первые 2 размерности. Это связано с тем, что один объект из выборки имеет размерность (maxlen, emb_size) и весь батч будет иметь размерность (batch_size, maxlen, emb_size).<br>\n",
    "\n",
    "\n",
    "После того как получены скрытые состояния, из них можно получить вероятности. Для этого можно, например, взять последнее скрытое состояние (можно использовать не только последнее) и применить к нему полносвязный слой, который вернет нужное количество чисел. Заметим, что лучше возвращать не сами вероятности, а логиты (то, что получается до применения softmax), не применяя softmax в конце, так как это будет удобно при подсчете лосса далее. <br>\n",
    "\n",
    "\n",
    "Попробуйте несколько разных rnn-ок (разные типы слоев или разные гиперпараметры) и разных сеток, для получения вероятностей по скрытым состояниям.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_dim=128,\n",
    "                 num_layers=1, out_size=len(chars),\n",
    "                 rnn_type=nn.RNN, device='cpu'):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        self.device = device\n",
    "        self.rnn_type = rnn_type\n",
    "        \n",
    "        self.embeddings = nn.Embedding(self.out_size, self.input_size) \n",
    "        self.rnn = self.rnn_type(input_size=self.input_size,\n",
    "                         hidden_size=self.hidden_dim,\n",
    "                         num_layers=self.num_layers,\n",
    "                         batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x, states = self.rnn(x)\n",
    "        logits = self.fc(x[:, -1, :].squeeze(0))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Model(device=device, rnn_type=nn.RNN).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для подсчета лосса. Здесь мы по сути решаем задачу классификации на vocab_len=len(chars) классов, поэтому в качестве лосса возьмем cross-entropy (neg log-likelihood). Заметим, что функция `F.cross_entropy` принимает на вход именно логиты, а не вероятности, именно поэтому лучше, чтобы модель возвращала логиты, не применяя softmax.<br>\n",
    "\n",
    "*Замечание*<br>\n",
    "Если вы при составлении датасета используете паддинг, то добавленные при помощи него символы не должны ничего вносить в лосс. То есть на тех местах, где истинный символ является специальным символом для паддинга, мы не обращаем внимания на предсказания. Иначе нейросеть может научиться всегда предсказывать этот специальный символ (так как он часто встречается и это будет минимизировать лосс). Есть несколько вариантов сделать это. Например, можно считать лосс так : <br>\n",
    "`criterion = nn.CrossEntropyLoss(ignore_index=pad_ix, size_average=True)\n",
    "criterion(logits, y_batch)`<br>\n",
    "вместо <br>\n",
    "`F.cross_entropy(logits, y_batch)`<br>\n",
    "Здесь pad_ix - число, которое мы поставили в соответствие специальному символу для паддинга ранее : Например, `char_indices['#']` если вы используете '#' в качестве символа для паддинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, X_batch, y_batch, pad_ix=char_indices[PAD]):\n",
    "    logits = model(X_batch)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_ix, size_average=True)\n",
    "    # rewrite it in case you use padding\n",
    "    return criterion(logits, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию генерации батчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batch_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        indices = np.arange(len(X))\n",
    "        \n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        ix = indices[start: start + batch_size]\n",
    "        yield torch.LongTensor(X[ix]).to(device), \\\n",
    "              torch.LongTensor(y[ix]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение. Это может занять какое-то время. Сэкономить время поможет https://colab.research.google.com или запускаться на ночь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs = 10, batch_size = 32, lr=1e-4):\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # На каждой эпохе делаем полный проход по данным\n",
    "        start_time = time.time()\n",
    "        model.train(True) # устанавливаем поведение dropout / batch_norm  в обучение\n",
    "        for X_batch, y_batch in iterate_minibatches(X_train, y_train,\n",
    "                                                    batch_size, True):\n",
    "            # Обучаемся на батче\n",
    "            loss = compute_loss(model, X_batch, y_batch)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        # Полный проход по валидации\n",
    "        # устанавливаем поведение dropout / batch_norm  в тестирование\n",
    "        model.train(False)\n",
    "        for X_batch, y_batch in iterate_minibatches(X_val, y_val,\n",
    "                                                    batch_size, False):\n",
    "            logits = model(X_batch)\n",
    "            loss = nn.CrossEntropyLoss(ignore_index=char_indices[PAD],\n",
    "                                       size_average=True)(\n",
    "                                       logits, y_batch) \n",
    "            # находим индексы максимумов\n",
    "            y_pred = logits.max(1)[1]\n",
    "            val_accuracy.append((y_batch == y_pred).type(\n",
    "                                torch.FloatTensor).mean().item())\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        # Печатаем результаты после каждой эпохи\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))\n",
    "    return model, train_loss, val_accuracy, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_rnn, train_loss_rnn, val_acc_rnn, _ = train(model_rnn,\n",
    "#                                                num_epochs=num_epochs,\n",
    "#                                                batch_size=batch_size)\n",
    "# torch.save(model_rnn.state_dict(), 'model_rnn')\n",
    "\n",
    "results = [(1.322897, 56.56)]  #результат последней оценки на валидации\n",
    "model_rnn.load_state_dict(torch.load('model_rnn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = Model(device=device, rnn_type=nn.GRU).to(device)\n",
    "# model_gru, train_loss_gru, val_acc_gru, _ = train(model_gru,\n",
    "#                                                num_epochs=num_epochs,\n",
    "#                                                batch_size=batch_size)\n",
    "# torch.save(model_gru.state_dict(), 'model_gru')\n",
    "results.append((1.154201, 57.80))\n",
    "model_gru.load_state_dict(torch.load('model_gru'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Model(device=device, rnn_type=nn.LSTM).to(device)\n",
    "# model_lstm, train_loss_lstm, val_acc_lstm, val_loss_lstm = train(model_lstm,\n",
    "#                                                   num_epochs=num_epochs,\n",
    "#                                                   batch_size=batch_size)\n",
    "# torch.save(model_lstm.state_dict(), 'model_lstm')\n",
    "results.append((1.136434, 58.02))\n",
    "model_lstm.load_state_dict(torch.load('model_lstm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 300 took 7.328s\n",
      "  training loss (in-iteration): \t3.197992\n",
      "  validation accuracy: \t\t\t17.64 %\n",
      "Epoch 2 of 300 took 7.120s\n",
      "  training loss (in-iteration): \t2.768501\n",
      "  validation accuracy: \t\t\t27.26 %\n",
      "Epoch 3 of 300 took 7.249s\n",
      "  training loss (in-iteration): \t2.564013\n",
      "  validation accuracy: \t\t\t30.12 %\n",
      "Epoch 4 of 300 took 7.060s\n",
      "  training loss (in-iteration): \t2.443618\n",
      "  validation accuracy: \t\t\t31.21 %\n",
      "Epoch 5 of 300 took 7.124s\n",
      "  training loss (in-iteration): \t2.360804\n",
      "  validation accuracy: \t\t\t32.32 %\n",
      "Epoch 6 of 300 took 7.213s\n",
      "  training loss (in-iteration): \t2.295135\n",
      "  validation accuracy: \t\t\t34.25 %\n",
      "Epoch 7 of 300 took 7.224s\n",
      "  training loss (in-iteration): \t2.239451\n",
      "  validation accuracy: \t\t\t36.17 %\n",
      "Epoch 8 of 300 took 7.118s\n",
      "  training loss (in-iteration): \t2.190694\n",
      "  validation accuracy: \t\t\t36.97 %\n",
      "Epoch 9 of 300 took 7.337s\n",
      "  training loss (in-iteration): \t2.147395\n",
      "  validation accuracy: \t\t\t38.35 %\n",
      "Epoch 10 of 300 took 7.032s\n",
      "  training loss (in-iteration): \t2.109532\n",
      "  validation accuracy: \t\t\t39.69 %\n",
      "Epoch 11 of 300 took 7.335s\n",
      "  training loss (in-iteration): \t2.075653\n",
      "  validation accuracy: \t\t\t40.60 %\n",
      "Epoch 12 of 300 took 7.025s\n",
      "  training loss (in-iteration): \t2.045129\n",
      "  validation accuracy: \t\t\t41.22 %\n",
      "Epoch 13 of 300 took 7.572s\n",
      "  training loss (in-iteration): \t2.017064\n",
      "  validation accuracy: \t\t\t42.06 %\n",
      "Epoch 14 of 300 took 7.276s\n",
      "  training loss (in-iteration): \t1.991872\n",
      "  validation accuracy: \t\t\t42.52 %\n",
      "Epoch 15 of 300 took 7.606s\n",
      "  training loss (in-iteration): \t1.968786\n",
      "  validation accuracy: \t\t\t42.98 %\n",
      "Epoch 16 of 300 took 7.527s\n",
      "  training loss (in-iteration): \t1.947854\n",
      "  validation accuracy: \t\t\t43.31 %\n",
      "Epoch 17 of 300 took 7.478s\n",
      "  training loss (in-iteration): \t1.927940\n",
      "  validation accuracy: \t\t\t43.52 %\n",
      "Epoch 18 of 300 took 7.621s\n",
      "  training loss (in-iteration): \t1.909707\n",
      "  validation accuracy: \t\t\t44.16 %\n",
      "Epoch 19 of 300 took 7.475s\n",
      "  training loss (in-iteration): \t1.892420\n",
      "  validation accuracy: \t\t\t44.42 %\n",
      "Epoch 20 of 300 took 7.411s\n",
      "  training loss (in-iteration): \t1.875997\n",
      "  validation accuracy: \t\t\t45.06 %\n",
      "Epoch 21 of 300 took 7.375s\n",
      "  training loss (in-iteration): \t1.860402\n",
      "  validation accuracy: \t\t\t45.19 %\n",
      "Epoch 22 of 300 took 7.762s\n",
      "  training loss (in-iteration): \t1.845777\n",
      "  validation accuracy: \t\t\t45.75 %\n",
      "Epoch 23 of 300 took 7.618s\n",
      "  training loss (in-iteration): \t1.831633\n",
      "  validation accuracy: \t\t\t45.85 %\n",
      "Epoch 24 of 300 took 7.608s\n",
      "  training loss (in-iteration): \t1.818384\n",
      "  validation accuracy: \t\t\t46.36 %\n",
      "Epoch 25 of 300 took 7.443s\n",
      "  training loss (in-iteration): \t1.805864\n",
      "  validation accuracy: \t\t\t46.63 %\n",
      "Epoch 26 of 300 took 7.413s\n",
      "  training loss (in-iteration): \t1.793606\n",
      "  validation accuracy: \t\t\t47.09 %\n",
      "Epoch 27 of 300 took 7.645s\n",
      "  training loss (in-iteration): \t1.781452\n",
      "  validation accuracy: \t\t\t47.14 %\n",
      "Epoch 28 of 300 took 7.463s\n",
      "  training loss (in-iteration): \t1.770128\n",
      "  validation accuracy: \t\t\t47.55 %\n",
      "Epoch 29 of 300 took 7.759s\n",
      "  training loss (in-iteration): \t1.759162\n",
      "  validation accuracy: \t\t\t47.90 %\n",
      "Epoch 30 of 300 took 7.568s\n",
      "  training loss (in-iteration): \t1.748772\n",
      "  validation accuracy: \t\t\t48.08 %\n",
      "Epoch 31 of 300 took 7.459s\n",
      "  training loss (in-iteration): \t1.738700\n",
      "  validation accuracy: \t\t\t48.31 %\n",
      "Epoch 32 of 300 took 7.672s\n",
      "  training loss (in-iteration): \t1.729136\n",
      "  validation accuracy: \t\t\t48.50 %\n",
      "Epoch 33 of 300 took 7.501s\n",
      "  training loss (in-iteration): \t1.719654\n",
      "  validation accuracy: \t\t\t48.75 %\n",
      "Epoch 34 of 300 took 7.613s\n",
      "  training loss (in-iteration): \t1.710302\n",
      "  validation accuracy: \t\t\t49.09 %\n",
      "Epoch 35 of 300 took 7.506s\n",
      "  training loss (in-iteration): \t1.701398\n",
      "  validation accuracy: \t\t\t49.14 %\n",
      "Epoch 36 of 300 took 7.507s\n",
      "  training loss (in-iteration): \t1.693087\n",
      "  validation accuracy: \t\t\t49.59 %\n",
      "Epoch 37 of 300 took 7.896s\n",
      "  training loss (in-iteration): \t1.684527\n",
      "  validation accuracy: \t\t\t49.74 %\n",
      "Epoch 38 of 300 took 7.435s\n",
      "  training loss (in-iteration): \t1.676194\n",
      "  validation accuracy: \t\t\t49.92 %\n",
      "Epoch 39 of 300 took 7.608s\n",
      "  training loss (in-iteration): \t1.668324\n",
      "  validation accuracy: \t\t\t50.10 %\n",
      "Epoch 40 of 300 took 7.540s\n",
      "  training loss (in-iteration): \t1.661045\n",
      "  validation accuracy: \t\t\t50.05 %\n",
      "Epoch 41 of 300 took 7.505s\n",
      "  training loss (in-iteration): \t1.653190\n",
      "  validation accuracy: \t\t\t50.40 %\n",
      "Epoch 42 of 300 took 7.550s\n",
      "  training loss (in-iteration): \t1.646133\n",
      "  validation accuracy: \t\t\t50.61 %\n",
      "Epoch 43 of 300 took 6.252s\n",
      "  training loss (in-iteration): \t1.639186\n",
      "  validation accuracy: \t\t\t50.70 %\n",
      "Epoch 44 of 300 took 5.754s\n",
      "  training loss (in-iteration): \t1.632544\n",
      "  validation accuracy: \t\t\t50.87 %\n",
      "Epoch 45 of 300 took 5.637s\n",
      "  training loss (in-iteration): \t1.625627\n",
      "  validation accuracy: \t\t\t50.96 %\n",
      "Epoch 46 of 300 took 5.723s\n",
      "  training loss (in-iteration): \t1.619279\n",
      "  validation accuracy: \t\t\t51.17 %\n",
      "Epoch 47 of 300 took 5.683s\n",
      "  training loss (in-iteration): \t1.612926\n",
      "  validation accuracy: \t\t\t51.25 %\n",
      "Epoch 48 of 300 took 5.678s\n",
      "  training loss (in-iteration): \t1.606878\n",
      "  validation accuracy: \t\t\t51.44 %\n",
      "Epoch 49 of 300 took 5.650s\n",
      "  training loss (in-iteration): \t1.601114\n",
      "  validation accuracy: \t\t\t51.51 %\n",
      "Epoch 50 of 300 took 5.726s\n",
      "  training loss (in-iteration): \t1.595087\n",
      "  validation accuracy: \t\t\t51.74 %\n",
      "Epoch 51 of 300 took 5.705s\n",
      "  training loss (in-iteration): \t1.589448\n",
      "  validation accuracy: \t\t\t51.94 %\n",
      "Epoch 52 of 300 took 5.665s\n",
      "  training loss (in-iteration): \t1.584117\n",
      "  validation accuracy: \t\t\t51.93 %\n",
      "Epoch 53 of 300 took 5.737s\n",
      "  training loss (in-iteration): \t1.578570\n",
      "  validation accuracy: \t\t\t51.83 %\n",
      "Epoch 54 of 300 took 5.742s\n",
      "  training loss (in-iteration): \t1.573327\n",
      "  validation accuracy: \t\t\t52.02 %\n",
      "Epoch 55 of 300 took 5.695s\n",
      "  training loss (in-iteration): \t1.568324\n",
      "  validation accuracy: \t\t\t51.99 %\n",
      "Epoch 56 of 300 took 5.645s\n",
      "  training loss (in-iteration): \t1.563145\n",
      "  validation accuracy: \t\t\t52.25 %\n",
      "Epoch 57 of 300 took 5.791s\n",
      "  training loss (in-iteration): \t1.558202\n",
      "  validation accuracy: \t\t\t52.37 %\n",
      "Epoch 58 of 300 took 5.784s\n",
      "  training loss (in-iteration): \t1.553407\n",
      "  validation accuracy: \t\t\t52.36 %\n",
      "Epoch 59 of 300 took 5.686s\n",
      "  training loss (in-iteration): \t1.548660\n",
      "  validation accuracy: \t\t\t52.40 %\n",
      "Epoch 60 of 300 took 5.775s\n",
      "  training loss (in-iteration): \t1.544019\n",
      "  validation accuracy: \t\t\t52.59 %\n",
      "Epoch 61 of 300 took 5.681s\n",
      "  training loss (in-iteration): \t1.539530\n",
      "  validation accuracy: \t\t\t52.79 %\n",
      "Epoch 62 of 300 took 5.692s\n",
      "  training loss (in-iteration): \t1.535051\n",
      "  validation accuracy: \t\t\t52.63 %\n",
      "Epoch 63 of 300 took 5.663s\n",
      "  training loss (in-iteration): \t1.530823\n",
      "  validation accuracy: \t\t\t53.03 %\n",
      "Epoch 64 of 300 took 5.727s\n",
      "  training loss (in-iteration): \t1.526272\n",
      "  validation accuracy: \t\t\t52.94 %\n",
      "Epoch 65 of 300 took 5.789s\n",
      "  training loss (in-iteration): \t1.522370\n",
      "  validation accuracy: \t\t\t53.08 %\n",
      "Epoch 66 of 300 took 5.622s\n",
      "  training loss (in-iteration): \t1.518153\n",
      "  validation accuracy: \t\t\t53.04 %\n",
      "Epoch 67 of 300 took 5.786s\n",
      "  training loss (in-iteration): \t1.514088\n",
      "  validation accuracy: \t\t\t53.27 %\n",
      "Epoch 68 of 300 took 5.683s\n",
      "  training loss (in-iteration): \t1.510303\n",
      "  validation accuracy: \t\t\t53.24 %\n",
      "Epoch 69 of 300 took 5.688s\n",
      "  training loss (in-iteration): \t1.506135\n",
      "  validation accuracy: \t\t\t53.41 %\n",
      "Epoch 70 of 300 took 5.723s\n",
      "  training loss (in-iteration): \t1.502263\n",
      "  validation accuracy: \t\t\t53.41 %\n",
      "Epoch 71 of 300 took 5.771s\n",
      "  training loss (in-iteration): \t1.498869\n",
      "  validation accuracy: \t\t\t53.47 %\n",
      "Epoch 72 of 300 took 5.746s\n",
      "  training loss (in-iteration): \t1.494697\n",
      "  validation accuracy: \t\t\t53.45 %\n",
      "Epoch 73 of 300 took 5.677s\n",
      "  training loss (in-iteration): \t1.491310\n",
      "  validation accuracy: \t\t\t53.64 %\n",
      "Epoch 74 of 300 took 5.773s\n",
      "  training loss (in-iteration): \t1.487669\n",
      "  validation accuracy: \t\t\t53.72 %\n",
      "Epoch 75 of 300 took 5.738s\n",
      "  training loss (in-iteration): \t1.484203\n",
      "  validation accuracy: \t\t\t53.74 %\n",
      "Epoch 76 of 300 took 5.684s\n",
      "  training loss (in-iteration): \t1.480177\n",
      "  validation accuracy: \t\t\t53.85 %\n",
      "Epoch 77 of 300 took 5.609s\n",
      "  training loss (in-iteration): \t1.476938\n",
      "  validation accuracy: \t\t\t53.87 %\n",
      "Epoch 78 of 300 took 5.722s\n",
      "  training loss (in-iteration): \t1.473471\n",
      "  validation accuracy: \t\t\t53.88 %\n",
      "Epoch 79 of 300 took 5.778s\n",
      "  training loss (in-iteration): \t1.470130\n",
      "  validation accuracy: \t\t\t53.96 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 of 300 took 5.680s\n",
      "  training loss (in-iteration): \t1.466709\n",
      "  validation accuracy: \t\t\t54.19 %\n",
      "Epoch 81 of 300 took 5.717s\n",
      "  training loss (in-iteration): \t1.463721\n",
      "  validation accuracy: \t\t\t54.23 %\n",
      "Epoch 82 of 300 took 5.699s\n",
      "  training loss (in-iteration): \t1.460642\n",
      "  validation accuracy: \t\t\t54.39 %\n",
      "Epoch 83 of 300 took 5.705s\n",
      "  training loss (in-iteration): \t1.457110\n",
      "  validation accuracy: \t\t\t54.35 %\n",
      "Epoch 84 of 300 took 5.666s\n",
      "  training loss (in-iteration): \t1.454434\n",
      "  validation accuracy: \t\t\t54.42 %\n",
      "Epoch 85 of 300 took 5.736s\n",
      "  training loss (in-iteration): \t1.451082\n",
      "  validation accuracy: \t\t\t54.42 %\n",
      "Epoch 86 of 300 took 5.722s\n",
      "  training loss (in-iteration): \t1.447922\n",
      "  validation accuracy: \t\t\t54.61 %\n",
      "Epoch 87 of 300 took 5.682s\n",
      "  training loss (in-iteration): \t1.444920\n",
      "  validation accuracy: \t\t\t54.57 %\n",
      "Epoch 88 of 300 took 5.726s\n",
      "  training loss (in-iteration): \t1.441958\n",
      "  validation accuracy: \t\t\t54.64 %\n",
      "Epoch 89 of 300 took 5.680s\n",
      "  training loss (in-iteration): \t1.439226\n",
      "  validation accuracy: \t\t\t54.78 %\n",
      "Epoch 90 of 300 took 5.696s\n",
      "  training loss (in-iteration): \t1.436025\n",
      "  validation accuracy: \t\t\t54.87 %\n",
      "Epoch 91 of 300 took 5.602s\n",
      "  training loss (in-iteration): \t1.433315\n",
      "  validation accuracy: \t\t\t54.77 %\n",
      "Epoch 92 of 300 took 5.740s\n",
      "  training loss (in-iteration): \t1.430332\n",
      "  validation accuracy: \t\t\t55.05 %\n",
      "Epoch 93 of 300 took 5.771s\n",
      "  training loss (in-iteration): \t1.427771\n",
      "  validation accuracy: \t\t\t54.98 %\n",
      "Epoch 94 of 300 took 5.676s\n",
      "  training loss (in-iteration): \t1.425208\n",
      "  validation accuracy: \t\t\t54.96 %\n",
      "Epoch 95 of 300 took 5.729s\n",
      "  training loss (in-iteration): \t1.422400\n",
      "  validation accuracy: \t\t\t55.10 %\n",
      "Epoch 96 of 300 took 5.702s\n",
      "  training loss (in-iteration): \t1.419597\n",
      "  validation accuracy: \t\t\t55.19 %\n",
      "Epoch 97 of 300 took 5.697s\n",
      "  training loss (in-iteration): \t1.416811\n",
      "  validation accuracy: \t\t\t55.27 %\n",
      "Epoch 98 of 300 took 5.716s\n",
      "  training loss (in-iteration): \t1.414377\n",
      "  validation accuracy: \t\t\t55.18 %\n",
      "Epoch 99 of 300 took 5.730s\n",
      "  training loss (in-iteration): \t1.411764\n",
      "  validation accuracy: \t\t\t55.12 %\n",
      "Epoch 100 of 300 took 5.771s\n",
      "  training loss (in-iteration): \t1.409054\n",
      "  validation accuracy: \t\t\t55.29 %\n",
      "Epoch 101 of 300 took 6.441s\n",
      "  training loss (in-iteration): \t1.406659\n",
      "  validation accuracy: \t\t\t55.28 %\n",
      "Epoch 102 of 300 took 7.937s\n",
      "  training loss (in-iteration): \t1.404062\n",
      "  validation accuracy: \t\t\t55.45 %\n",
      "Epoch 103 of 300 took 7.480s\n",
      "  training loss (in-iteration): \t1.401658\n",
      "  validation accuracy: \t\t\t55.53 %\n",
      "Epoch 104 of 300 took 7.315s\n",
      "  training loss (in-iteration): \t1.398805\n",
      "  validation accuracy: \t\t\t55.54 %\n",
      "Epoch 105 of 300 took 7.557s\n",
      "  training loss (in-iteration): \t1.396656\n",
      "  validation accuracy: \t\t\t55.45 %\n",
      "Epoch 106 of 300 took 7.377s\n",
      "  training loss (in-iteration): \t1.394181\n",
      "  validation accuracy: \t\t\t55.46 %\n",
      "Epoch 107 of 300 took 7.377s\n",
      "  training loss (in-iteration): \t1.391725\n",
      "  validation accuracy: \t\t\t55.73 %\n",
      "Epoch 108 of 300 took 7.356s\n",
      "  training loss (in-iteration): \t1.389406\n",
      "  validation accuracy: \t\t\t55.79 %\n",
      "Epoch 109 of 300 took 7.385s\n",
      "  training loss (in-iteration): \t1.387269\n",
      "  validation accuracy: \t\t\t55.63 %\n",
      "Epoch 110 of 300 took 7.291s\n",
      "  training loss (in-iteration): \t1.384911\n",
      "  validation accuracy: \t\t\t55.76 %\n",
      "Epoch 111 of 300 took 7.712s\n",
      "  training loss (in-iteration): \t1.382594\n",
      "  validation accuracy: \t\t\t55.76 %\n",
      "Epoch 112 of 300 took 7.393s\n",
      "  training loss (in-iteration): \t1.380096\n",
      "  validation accuracy: \t\t\t55.95 %\n",
      "Epoch 113 of 300 took 7.537s\n",
      "  training loss (in-iteration): \t1.378168\n",
      "  validation accuracy: \t\t\t56.17 %\n",
      "Epoch 114 of 300 took 7.352s\n",
      "  training loss (in-iteration): \t1.375745\n",
      "  validation accuracy: \t\t\t55.91 %\n",
      "Epoch 115 of 300 took 7.577s\n",
      "  training loss (in-iteration): \t1.373502\n",
      "  validation accuracy: \t\t\t55.86 %\n",
      "Epoch 116 of 300 took 7.412s\n",
      "  training loss (in-iteration): \t1.371607\n",
      "  validation accuracy: \t\t\t55.90 %\n",
      "Epoch 117 of 300 took 7.397s\n",
      "  training loss (in-iteration): \t1.369166\n",
      "  validation accuracy: \t\t\t56.10 %\n",
      "Epoch 118 of 300 took 7.599s\n",
      "  training loss (in-iteration): \t1.367312\n",
      "  validation accuracy: \t\t\t56.02 %\n",
      "Epoch 119 of 300 took 7.490s\n",
      "  training loss (in-iteration): \t1.364549\n",
      "  validation accuracy: \t\t\t55.97 %\n",
      "Epoch 120 of 300 took 7.555s\n",
      "  training loss (in-iteration): \t1.362830\n",
      "  validation accuracy: \t\t\t56.27 %\n",
      "Epoch 121 of 300 took 7.615s\n",
      "  training loss (in-iteration): \t1.360605\n",
      "  validation accuracy: \t\t\t56.31 %\n",
      "Epoch 122 of 300 took 7.716s\n",
      "  training loss (in-iteration): \t1.358409\n",
      "  validation accuracy: \t\t\t56.09 %\n",
      "Epoch 123 of 300 took 7.458s\n",
      "  training loss (in-iteration): \t1.356519\n",
      "  validation accuracy: \t\t\t56.11 %\n",
      "Epoch 124 of 300 took 7.584s\n",
      "  training loss (in-iteration): \t1.354614\n",
      "  validation accuracy: \t\t\t56.26 %\n",
      "Epoch 125 of 300 took 7.545s\n",
      "  training loss (in-iteration): \t1.352368\n",
      "  validation accuracy: \t\t\t56.22 %\n",
      "Epoch 126 of 300 took 7.539s\n",
      "  training loss (in-iteration): \t1.350556\n",
      "  validation accuracy: \t\t\t56.09 %\n",
      "Epoch 127 of 300 took 7.661s\n",
      "  training loss (in-iteration): \t1.348581\n",
      "  validation accuracy: \t\t\t56.34 %\n",
      "Epoch 128 of 300 took 7.492s\n",
      "  training loss (in-iteration): \t1.346564\n",
      "  validation accuracy: \t\t\t56.42 %\n",
      "Epoch 129 of 300 took 7.430s\n",
      "  training loss (in-iteration): \t1.344327\n",
      "  validation accuracy: \t\t\t56.30 %\n",
      "Epoch 130 of 300 took 7.606s\n",
      "  training loss (in-iteration): \t1.342493\n",
      "  validation accuracy: \t\t\t56.42 %\n",
      "Epoch 131 of 300 took 7.496s\n",
      "  training loss (in-iteration): \t1.340523\n",
      "  validation accuracy: \t\t\t56.24 %\n",
      "Epoch 132 of 300 took 7.434s\n",
      "  training loss (in-iteration): \t1.338813\n",
      "  validation accuracy: \t\t\t56.30 %\n",
      "Epoch 133 of 300 took 7.436s\n",
      "  training loss (in-iteration): \t1.336785\n",
      "  validation accuracy: \t\t\t56.52 %\n",
      "Epoch 134 of 300 took 7.806s\n",
      "  training loss (in-iteration): \t1.335044\n",
      "  validation accuracy: \t\t\t56.46 %\n",
      "Epoch 135 of 300 took 7.556s\n",
      "  training loss (in-iteration): \t1.333210\n",
      "  validation accuracy: \t\t\t56.37 %\n",
      "Epoch 136 of 300 took 7.659s\n",
      "  training loss (in-iteration): \t1.331294\n",
      "  validation accuracy: \t\t\t56.64 %\n",
      "Epoch 137 of 300 took 7.426s\n",
      "  training loss (in-iteration): \t1.329475\n",
      "  validation accuracy: \t\t\t56.55 %\n",
      "Epoch 138 of 300 took 7.449s\n",
      "  training loss (in-iteration): \t1.327625\n",
      "  validation accuracy: \t\t\t56.64 %\n",
      "Epoch 139 of 300 took 7.816s\n",
      "  training loss (in-iteration): \t1.325497\n",
      "  validation accuracy: \t\t\t56.52 %\n",
      "Epoch 140 of 300 took 7.607s\n",
      "  training loss (in-iteration): \t1.324025\n",
      "  validation accuracy: \t\t\t56.45 %\n",
      "Epoch 141 of 300 took 7.646s\n",
      "  training loss (in-iteration): \t1.322265\n",
      "  validation accuracy: \t\t\t56.56 %\n",
      "Epoch 142 of 300 took 7.622s\n",
      "  training loss (in-iteration): \t1.320361\n",
      "  validation accuracy: \t\t\t56.79 %\n",
      "Epoch 143 of 300 took 7.579s\n",
      "  training loss (in-iteration): \t1.318552\n",
      "  validation accuracy: \t\t\t56.56 %\n",
      "Epoch 144 of 300 took 7.408s\n",
      "  training loss (in-iteration): \t1.317081\n",
      "  validation accuracy: \t\t\t56.71 %\n",
      "Epoch 145 of 300 took 7.464s\n",
      "  training loss (in-iteration): \t1.315117\n",
      "  validation accuracy: \t\t\t56.52 %\n",
      "Epoch 146 of 300 took 7.543s\n",
      "  training loss (in-iteration): \t1.313457\n",
      "  validation accuracy: \t\t\t56.72 %\n",
      "Epoch 147 of 300 took 7.625s\n",
      "  training loss (in-iteration): \t1.311744\n",
      "  validation accuracy: \t\t\t56.71 %\n",
      "Epoch 148 of 300 took 7.451s\n",
      "  training loss (in-iteration): \t1.310010\n",
      "  validation accuracy: \t\t\t56.79 %\n",
      "Epoch 149 of 300 took 7.502s\n",
      "  training loss (in-iteration): \t1.308233\n",
      "  validation accuracy: \t\t\t56.90 %\n",
      "Epoch 150 of 300 took 5.721s\n",
      "  training loss (in-iteration): \t1.306525\n",
      "  validation accuracy: \t\t\t56.97 %\n",
      "Epoch 151 of 300 took 5.764s\n",
      "  training loss (in-iteration): \t1.305184\n",
      "  validation accuracy: \t\t\t56.89 %\n",
      "Epoch 152 of 300 took 5.697s\n",
      "  training loss (in-iteration): \t1.303352\n",
      "  validation accuracy: \t\t\t56.95 %\n",
      "Epoch 153 of 300 took 5.663s\n",
      "  training loss (in-iteration): \t1.301375\n",
      "  validation accuracy: \t\t\t56.85 %\n",
      "Epoch 154 of 300 took 5.685s\n",
      "  training loss (in-iteration): \t1.299952\n",
      "  validation accuracy: \t\t\t56.98 %\n",
      "Epoch 155 of 300 took 5.814s\n",
      "  training loss (in-iteration): \t1.298258\n",
      "  validation accuracy: \t\t\t57.04 %\n",
      "Epoch 156 of 300 took 5.741s\n",
      "  training loss (in-iteration): \t1.296472\n",
      "  validation accuracy: \t\t\t57.19 %\n",
      "Epoch 157 of 300 took 5.694s\n",
      "  training loss (in-iteration): \t1.295025\n",
      "  validation accuracy: \t\t\t57.03 %\n",
      "Epoch 158 of 300 took 5.681s\n",
      "  training loss (in-iteration): \t1.293327\n",
      "  validation accuracy: \t\t\t56.88 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 of 300 took 5.694s\n",
      "  training loss (in-iteration): \t1.291712\n",
      "  validation accuracy: \t\t\t57.02 %\n",
      "Epoch 160 of 300 took 5.670s\n",
      "  training loss (in-iteration): \t1.290289\n",
      "  validation accuracy: \t\t\t57.05 %\n",
      "Epoch 161 of 300 took 5.687s\n",
      "  training loss (in-iteration): \t1.288582\n",
      "  validation accuracy: \t\t\t57.06 %\n",
      "Epoch 162 of 300 took 5.741s\n",
      "  training loss (in-iteration): \t1.287033\n",
      "  validation accuracy: \t\t\t57.23 %\n",
      "Epoch 163 of 300 took 5.768s\n",
      "  training loss (in-iteration): \t1.285391\n",
      "  validation accuracy: \t\t\t57.06 %\n",
      "Epoch 164 of 300 took 5.774s\n",
      "  training loss (in-iteration): \t1.283960\n",
      "  validation accuracy: \t\t\t57.22 %\n",
      "Epoch 165 of 300 took 5.692s\n",
      "  training loss (in-iteration): \t1.282621\n",
      "  validation accuracy: \t\t\t56.99 %\n",
      "Epoch 166 of 300 took 5.728s\n",
      "  training loss (in-iteration): \t1.280766\n",
      "  validation accuracy: \t\t\t57.15 %\n",
      "Epoch 167 of 300 took 5.651s\n",
      "  training loss (in-iteration): \t1.279384\n",
      "  validation accuracy: \t\t\t57.20 %\n",
      "Epoch 168 of 300 took 5.756s\n",
      "  training loss (in-iteration): \t1.278147\n",
      "  validation accuracy: \t\t\t57.17 %\n",
      "Epoch 169 of 300 took 5.746s\n",
      "  training loss (in-iteration): \t1.276347\n",
      "  validation accuracy: \t\t\t57.28 %\n",
      "Epoch 170 of 300 took 5.785s\n",
      "  training loss (in-iteration): \t1.274563\n",
      "  validation accuracy: \t\t\t57.30 %\n",
      "Epoch 171 of 300 took 5.760s\n",
      "  training loss (in-iteration): \t1.273406\n",
      "  validation accuracy: \t\t\t57.30 %\n",
      "Epoch 172 of 300 took 5.713s\n",
      "  training loss (in-iteration): \t1.271860\n",
      "  validation accuracy: \t\t\t57.22 %\n",
      "Epoch 173 of 300 took 5.729s\n",
      "  training loss (in-iteration): \t1.270285\n",
      "  validation accuracy: \t\t\t57.18 %\n",
      "Epoch 174 of 300 took 5.689s\n",
      "  training loss (in-iteration): \t1.269014\n",
      "  validation accuracy: \t\t\t57.19 %\n",
      "Epoch 175 of 300 took 5.769s\n",
      "  training loss (in-iteration): \t1.267430\n",
      "  validation accuracy: \t\t\t57.32 %\n",
      "Epoch 176 of 300 took 6.169s\n",
      "  training loss (in-iteration): \t1.265609\n",
      "  validation accuracy: \t\t\t57.26 %\n",
      "Epoch 177 of 300 took 6.062s\n",
      "  training loss (in-iteration): \t1.264367\n",
      "  validation accuracy: \t\t\t57.25 %\n",
      "Epoch 178 of 300 took 5.733s\n",
      "  training loss (in-iteration): \t1.262995\n",
      "  validation accuracy: \t\t\t57.23 %\n",
      "Epoch 179 of 300 took 5.745s\n",
      "  training loss (in-iteration): \t1.261464\n",
      "  validation accuracy: \t\t\t57.30 %\n",
      "Epoch 180 of 300 took 5.711s\n",
      "  training loss (in-iteration): \t1.260060\n",
      "  validation accuracy: \t\t\t57.47 %\n",
      "Epoch 181 of 300 took 5.672s\n",
      "  training loss (in-iteration): \t1.258718\n",
      "  validation accuracy: \t\t\t57.29 %\n",
      "Epoch 182 of 300 took 5.702s\n",
      "  training loss (in-iteration): \t1.257396\n",
      "  validation accuracy: \t\t\t57.30 %\n",
      "Epoch 183 of 300 took 5.819s\n",
      "  training loss (in-iteration): \t1.255874\n",
      "  validation accuracy: \t\t\t57.23 %\n",
      "Epoch 184 of 300 took 5.827s\n",
      "  training loss (in-iteration): \t1.254788\n",
      "  validation accuracy: \t\t\t57.07 %\n",
      "Epoch 185 of 300 took 5.708s\n",
      "  training loss (in-iteration): \t1.253430\n",
      "  validation accuracy: \t\t\t57.37 %\n",
      "Epoch 186 of 300 took 5.772s\n",
      "  training loss (in-iteration): \t1.251880\n",
      "  validation accuracy: \t\t\t57.39 %\n",
      "Epoch 187 of 300 took 5.683s\n",
      "  training loss (in-iteration): \t1.250602\n",
      "  validation accuracy: \t\t\t57.39 %\n",
      "Epoch 188 of 300 took 5.677s\n",
      "  training loss (in-iteration): \t1.249184\n",
      "  validation accuracy: \t\t\t57.48 %\n",
      "Epoch 189 of 300 took 5.771s\n",
      "  training loss (in-iteration): \t1.247765\n",
      "  validation accuracy: \t\t\t57.47 %\n",
      "Epoch 190 of 300 took 5.765s\n",
      "  training loss (in-iteration): \t1.246141\n",
      "  validation accuracy: \t\t\t57.54 %\n",
      "Epoch 191 of 300 took 5.762s\n",
      "  training loss (in-iteration): \t1.244872\n",
      "  validation accuracy: \t\t\t57.47 %\n",
      "Epoch 192 of 300 took 5.703s\n",
      "  training loss (in-iteration): \t1.243732\n",
      "  validation accuracy: \t\t\t57.44 %\n",
      "Epoch 193 of 300 took 5.749s\n",
      "  training loss (in-iteration): \t1.242278\n",
      "  validation accuracy: \t\t\t57.41 %\n",
      "Epoch 194 of 300 took 5.675s\n",
      "  training loss (in-iteration): \t1.240800\n",
      "  validation accuracy: \t\t\t57.32 %\n",
      "Epoch 195 of 300 took 5.679s\n",
      "  training loss (in-iteration): \t1.239655\n",
      "  validation accuracy: \t\t\t57.34 %\n",
      "Epoch 196 of 300 took 5.776s\n",
      "  training loss (in-iteration): \t1.238299\n",
      "  validation accuracy: \t\t\t57.35 %\n",
      "Epoch 197 of 300 took 7.360s\n",
      "  training loss (in-iteration): \t1.236809\n",
      "  validation accuracy: \t\t\t57.52 %\n",
      "Epoch 198 of 300 took 5.824s\n",
      "  training loss (in-iteration): \t1.235613\n",
      "  validation accuracy: \t\t\t57.43 %\n",
      "Epoch 199 of 300 took 5.708s\n",
      "  training loss (in-iteration): \t1.233988\n",
      "  validation accuracy: \t\t\t57.58 %\n",
      "Epoch 200 of 300 took 5.699s\n",
      "  training loss (in-iteration): \t1.233149\n",
      "  validation accuracy: \t\t\t57.61 %\n",
      "Epoch 201 of 300 took 7.046s\n",
      "  training loss (in-iteration): \t1.231497\n",
      "  validation accuracy: \t\t\t57.60 %\n",
      "Epoch 202 of 300 took 6.836s\n",
      "  training loss (in-iteration): \t1.230166\n",
      "  validation accuracy: \t\t\t57.50 %\n",
      "Epoch 203 of 300 took 6.770s\n",
      "  training loss (in-iteration): \t1.228945\n",
      "  validation accuracy: \t\t\t57.56 %\n",
      "Epoch 204 of 300 took 5.759s\n",
      "  training loss (in-iteration): \t1.227721\n",
      "  validation accuracy: \t\t\t57.51 %\n",
      "Epoch 205 of 300 took 5.786s\n",
      "  training loss (in-iteration): \t1.226346\n",
      "  validation accuracy: \t\t\t57.58 %\n",
      "Epoch 206 of 300 took 7.342s\n",
      "  training loss (in-iteration): \t1.225149\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 207 of 300 took 7.674s\n",
      "  training loss (in-iteration): \t1.223960\n",
      "  validation accuracy: \t\t\t57.57 %\n",
      "Epoch 208 of 300 took 7.742s\n",
      "  training loss (in-iteration): \t1.222583\n",
      "  validation accuracy: \t\t\t57.39 %\n",
      "Epoch 209 of 300 took 7.690s\n",
      "  training loss (in-iteration): \t1.221190\n",
      "  validation accuracy: \t\t\t57.78 %\n",
      "Epoch 210 of 300 took 7.750s\n",
      "  training loss (in-iteration): \t1.220040\n",
      "  validation accuracy: \t\t\t57.40 %\n",
      "Epoch 211 of 300 took 7.448s\n",
      "  training loss (in-iteration): \t1.218782\n",
      "  validation accuracy: \t\t\t57.70 %\n",
      "Epoch 212 of 300 took 7.684s\n",
      "  training loss (in-iteration): \t1.217356\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 213 of 300 took 7.486s\n",
      "  training loss (in-iteration): \t1.216165\n",
      "  validation accuracy: \t\t\t57.48 %\n",
      "Epoch 214 of 300 took 7.482s\n",
      "  training loss (in-iteration): \t1.214928\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 215 of 300 took 7.655s\n",
      "  training loss (in-iteration): \t1.213558\n",
      "  validation accuracy: \t\t\t57.63 %\n",
      "Epoch 216 of 300 took 7.462s\n",
      "  training loss (in-iteration): \t1.212655\n",
      "  validation accuracy: \t\t\t57.61 %\n",
      "Epoch 217 of 300 took 7.660s\n",
      "  training loss (in-iteration): \t1.211310\n",
      "  validation accuracy: \t\t\t57.68 %\n",
      "Epoch 218 of 300 took 7.484s\n",
      "  training loss (in-iteration): \t1.210001\n",
      "  validation accuracy: \t\t\t57.64 %\n",
      "Epoch 219 of 300 took 7.767s\n",
      "  training loss (in-iteration): \t1.208656\n",
      "  validation accuracy: \t\t\t57.71 %\n",
      "Epoch 220 of 300 took 7.511s\n",
      "  training loss (in-iteration): \t1.208020\n",
      "  validation accuracy: \t\t\t57.71 %\n",
      "Epoch 221 of 300 took 7.774s\n",
      "  training loss (in-iteration): \t1.206289\n",
      "  validation accuracy: \t\t\t57.60 %\n",
      "Epoch 222 of 300 took 7.589s\n",
      "  training loss (in-iteration): \t1.205265\n",
      "  validation accuracy: \t\t\t57.77 %\n",
      "Epoch 223 of 300 took 7.633s\n",
      "  training loss (in-iteration): \t1.204078\n",
      "  validation accuracy: \t\t\t57.61 %\n",
      "Epoch 224 of 300 took 7.685s\n",
      "  training loss (in-iteration): \t1.203114\n",
      "  validation accuracy: \t\t\t57.84 %\n",
      "Epoch 225 of 300 took 7.585s\n",
      "  training loss (in-iteration): \t1.201285\n",
      "  validation accuracy: \t\t\t57.82 %\n",
      "Epoch 226 of 300 took 7.771s\n",
      "  training loss (in-iteration): \t1.200363\n",
      "  validation accuracy: \t\t\t57.68 %\n",
      "Epoch 227 of 300 took 7.661s\n",
      "  training loss (in-iteration): \t1.199103\n",
      "  validation accuracy: \t\t\t57.68 %\n",
      "Epoch 228 of 300 took 7.741s\n",
      "  training loss (in-iteration): \t1.197840\n",
      "  validation accuracy: \t\t\t57.72 %\n",
      "Epoch 229 of 300 took 7.860s\n",
      "  training loss (in-iteration): \t1.196655\n",
      "  validation accuracy: \t\t\t57.58 %\n",
      "Epoch 230 of 300 took 7.557s\n",
      "  training loss (in-iteration): \t1.195556\n",
      "  validation accuracy: \t\t\t57.55 %\n",
      "Epoch 231 of 300 took 7.764s\n",
      "  training loss (in-iteration): \t1.194301\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 232 of 300 took 7.555s\n",
      "  training loss (in-iteration): \t1.193300\n",
      "  validation accuracy: \t\t\t57.77 %\n",
      "Epoch 233 of 300 took 7.797s\n",
      "  training loss (in-iteration): \t1.191919\n",
      "  validation accuracy: \t\t\t57.58 %\n",
      "Epoch 234 of 300 took 7.879s\n",
      "  training loss (in-iteration): \t1.190586\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 235 of 300 took 7.580s\n",
      "  training loss (in-iteration): \t1.189898\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 236 of 300 took 7.824s\n",
      "  training loss (in-iteration): \t1.188454\n",
      "  validation accuracy: \t\t\t57.57 %\n",
      "Epoch 237 of 300 took 7.547s\n",
      "  training loss (in-iteration): \t1.187493\n",
      "  validation accuracy: \t\t\t57.60 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 of 300 took 7.910s\n",
      "  training loss (in-iteration): \t1.186244\n",
      "  validation accuracy: \t\t\t57.54 %\n",
      "Epoch 239 of 300 took 7.902s\n",
      "  training loss (in-iteration): \t1.185283\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 240 of 300 took 7.623s\n",
      "  training loss (in-iteration): \t1.184103\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 241 of 300 took 7.853s\n",
      "  training loss (in-iteration): \t1.182776\n",
      "  validation accuracy: \t\t\t57.74 %\n",
      "Epoch 242 of 300 took 7.582s\n",
      "  training loss (in-iteration): \t1.181573\n",
      "  validation accuracy: \t\t\t57.68 %\n",
      "Epoch 243 of 300 took 7.797s\n",
      "  training loss (in-iteration): \t1.180588\n",
      "  validation accuracy: \t\t\t57.82 %\n",
      "Epoch 244 of 300 took 7.659s\n",
      "  training loss (in-iteration): \t1.179306\n",
      "  validation accuracy: \t\t\t57.78 %\n",
      "Epoch 245 of 300 took 7.804s\n",
      "  training loss (in-iteration): \t1.178649\n",
      "  validation accuracy: \t\t\t57.74 %\n",
      "Epoch 246 of 300 took 7.918s\n",
      "  training loss (in-iteration): \t1.177295\n",
      "  validation accuracy: \t\t\t57.69 %\n",
      "Epoch 247 of 300 took 7.822s\n",
      "  training loss (in-iteration): \t1.175926\n",
      "  validation accuracy: \t\t\t57.67 %\n",
      "Epoch 248 of 300 took 7.731s\n",
      "  training loss (in-iteration): \t1.174907\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 249 of 300 took 7.848s\n",
      "  training loss (in-iteration): \t1.173332\n",
      "  validation accuracy: \t\t\t57.81 %\n",
      "Epoch 250 of 300 took 7.544s\n",
      "  training loss (in-iteration): \t1.172750\n",
      "  validation accuracy: \t\t\t57.81 %\n",
      "Epoch 251 of 300 took 7.786s\n",
      "  training loss (in-iteration): \t1.171494\n",
      "  validation accuracy: \t\t\t57.92 %\n",
      "Epoch 252 of 300 took 7.846s\n",
      "  training loss (in-iteration): \t1.170255\n",
      "  validation accuracy: \t\t\t57.79 %\n",
      "Epoch 253 of 300 took 7.627s\n",
      "  training loss (in-iteration): \t1.169214\n",
      "  validation accuracy: \t\t\t57.61 %\n",
      "Epoch 254 of 300 took 5.810s\n",
      "  training loss (in-iteration): \t1.168302\n",
      "  validation accuracy: \t\t\t57.65 %\n",
      "Epoch 255 of 300 took 5.753s\n",
      "  training loss (in-iteration): \t1.166899\n",
      "  validation accuracy: \t\t\t57.75 %\n",
      "Epoch 256 of 300 took 5.751s\n",
      "  training loss (in-iteration): \t1.166196\n",
      "  validation accuracy: \t\t\t57.86 %\n",
      "Epoch 257 of 300 took 5.739s\n",
      "  training loss (in-iteration): \t1.164622\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 258 of 300 took 5.661s\n",
      "  training loss (in-iteration): \t1.163464\n",
      "  validation accuracy: \t\t\t57.88 %\n",
      "Epoch 259 of 300 took 5.696s\n",
      "  training loss (in-iteration): \t1.162530\n",
      "  validation accuracy: \t\t\t57.82 %\n",
      "Epoch 260 of 300 took 5.824s\n",
      "  training loss (in-iteration): \t1.161119\n",
      "  validation accuracy: \t\t\t57.47 %\n",
      "Epoch 261 of 300 took 5.829s\n",
      "  training loss (in-iteration): \t1.160416\n",
      "  validation accuracy: \t\t\t57.54 %\n",
      "Epoch 262 of 300 took 5.795s\n",
      "  training loss (in-iteration): \t1.159457\n",
      "  validation accuracy: \t\t\t57.74 %\n",
      "Epoch 263 of 300 took 5.743s\n",
      "  training loss (in-iteration): \t1.158364\n",
      "  validation accuracy: \t\t\t57.88 %\n",
      "Epoch 264 of 300 took 5.722s\n",
      "  training loss (in-iteration): \t1.157375\n",
      "  validation accuracy: \t\t\t57.72 %\n",
      "Epoch 265 of 300 took 5.673s\n",
      "  training loss (in-iteration): \t1.156249\n",
      "  validation accuracy: \t\t\t57.74 %\n",
      "Epoch 266 of 300 took 5.710s\n",
      "  training loss (in-iteration): \t1.155259\n",
      "  validation accuracy: \t\t\t57.76 %\n",
      "Epoch 267 of 300 took 5.845s\n",
      "  training loss (in-iteration): \t1.153838\n",
      "  validation accuracy: \t\t\t57.81 %\n",
      "Epoch 268 of 300 took 5.813s\n",
      "  training loss (in-iteration): \t1.153048\n",
      "  validation accuracy: \t\t\t57.77 %\n",
      "Epoch 269 of 300 took 5.762s\n",
      "  training loss (in-iteration): \t1.151746\n",
      "  validation accuracy: \t\t\t57.60 %\n",
      "Epoch 270 of 300 took 5.699s\n",
      "  training loss (in-iteration): \t1.151087\n",
      "  validation accuracy: \t\t\t57.85 %\n",
      "Epoch 271 of 300 took 5.686s\n",
      "  training loss (in-iteration): \t1.149539\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 272 of 300 took 5.697s\n",
      "  training loss (in-iteration): \t1.149094\n",
      "  validation accuracy: \t\t\t57.98 %\n",
      "Epoch 273 of 300 took 5.717s\n",
      "  training loss (in-iteration): \t1.147547\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 274 of 300 took 5.808s\n",
      "  training loss (in-iteration): \t1.146654\n",
      "  validation accuracy: \t\t\t58.03 %\n",
      "Epoch 275 of 300 took 5.762s\n",
      "  training loss (in-iteration): \t1.145634\n",
      "  validation accuracy: \t\t\t57.77 %\n",
      "Epoch 276 of 300 took 5.784s\n",
      "  training loss (in-iteration): \t1.144395\n",
      "  validation accuracy: \t\t\t58.05 %\n",
      "Epoch 277 of 300 took 5.755s\n",
      "  training loss (in-iteration): \t1.143601\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 278 of 300 took 5.705s\n",
      "  training loss (in-iteration): \t1.142443\n",
      "  validation accuracy: \t\t\t57.92 %\n",
      "Epoch 279 of 300 took 5.687s\n",
      "  training loss (in-iteration): \t1.141305\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 280 of 300 took 5.755s\n",
      "  training loss (in-iteration): \t1.140429\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 281 of 300 took 5.743s\n",
      "  training loss (in-iteration): \t1.139450\n",
      "  validation accuracy: \t\t\t57.94 %\n",
      "Epoch 282 of 300 took 5.814s\n",
      "  training loss (in-iteration): \t1.138275\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 283 of 300 took 5.703s\n",
      "  training loss (in-iteration): \t1.137115\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 284 of 300 took 5.754s\n",
      "  training loss (in-iteration): \t1.136467\n",
      "  validation accuracy: \t\t\t57.97 %\n",
      "Epoch 285 of 300 took 5.730s\n",
      "  training loss (in-iteration): \t1.134815\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 286 of 300 took 5.751s\n",
      "  training loss (in-iteration): \t1.134381\n",
      "  validation accuracy: \t\t\t58.00 %\n",
      "Epoch 287 of 300 took 5.732s\n",
      "  training loss (in-iteration): \t1.133443\n",
      "  validation accuracy: \t\t\t57.77 %\n",
      "Epoch 288 of 300 took 6.393s\n",
      "  training loss (in-iteration): \t1.132379\n",
      "  validation accuracy: \t\t\t57.93 %\n",
      "Epoch 289 of 300 took 11.641s\n",
      "  training loss (in-iteration): \t1.131088\n",
      "  validation accuracy: \t\t\t57.76 %\n",
      "Epoch 290 of 300 took 11.834s\n",
      "  training loss (in-iteration): \t1.130090\n",
      "  validation accuracy: \t\t\t57.87 %\n",
      "Epoch 291 of 300 took 11.629s\n",
      "  training loss (in-iteration): \t1.129013\n",
      "  validation accuracy: \t\t\t57.80 %\n",
      "Epoch 292 of 300 took 10.187s\n",
      "  training loss (in-iteration): \t1.128062\n",
      "  validation accuracy: \t\t\t57.95 %\n",
      "Epoch 293 of 300 took 5.667s\n",
      "  training loss (in-iteration): \t1.127137\n",
      "  validation accuracy: \t\t\t57.70 %\n",
      "Epoch 294 of 300 took 5.760s\n",
      "  training loss (in-iteration): \t1.126156\n",
      "  validation accuracy: \t\t\t57.92 %\n",
      "Epoch 295 of 300 took 5.804s\n",
      "  training loss (in-iteration): \t1.125320\n",
      "  validation accuracy: \t\t\t57.77 %\n",
      "Epoch 296 of 300 took 5.750s\n",
      "  training loss (in-iteration): \t1.124104\n",
      "  validation accuracy: \t\t\t57.89 %\n",
      "Epoch 297 of 300 took 5.690s\n",
      "  training loss (in-iteration): \t1.123202\n",
      "  validation accuracy: \t\t\t57.74 %\n",
      "Epoch 298 of 300 took 5.687s\n",
      "  training loss (in-iteration): \t1.121979\n",
      "  validation accuracy: \t\t\t57.99 %\n",
      "Epoch 299 of 300 took 5.726s\n",
      "  training loss (in-iteration): \t1.121144\n",
      "  validation accuracy: \t\t\t58.00 %\n",
      "Epoch 300 of 300 took 5.674s\n",
      "  training loss (in-iteration): \t1.120251\n",
      "  validation accuracy: \t\t\t57.92 %\n"
     ]
    }
   ],
   "source": [
    "model_lstm2 = Model(device=device, rnn_type=nn.LSTM, num_layers=2).to(device)\n",
    "model_lstm2, train_loss_lstm, val_acc_lstm, val_loss_lstm = train(model_lstm2,\n",
    "                                                  num_epochs=300,\n",
    "                                                  batch_size=batch_size, lr=5e-5)\n",
    "torch.save(model_lstm2.state_dict(), 'model_lstm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append((1.120251, 57.92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_loss_lstm[::50], label='train')\n",
    "plt.plot(np.linspace(0, len(train_loss_lstm[::50]),\n",
    "                     len(val_loss_lstm[::50])),\n",
    "                     val_loss_lstm[::50], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(val_acc_lstm[::20], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лосс и accuracy на валидации выходят на плато, значит мы остановились не слишком рано. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним разные типы RNN-ок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>1.322897</td>\n",
       "      <td>56.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>1.154201</td>\n",
       "      <td>57.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>1.136434</td>\n",
       "      <td>58.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM2</th>\n",
       "      <td>1.120251</td>\n",
       "      <td>57.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train loss  Accuracy\n",
       "RNN      1.322897     56.56\n",
       "GRU      1.154201     57.80\n",
       "LSTM     1.136434     58.02\n",
       "LSTM2    1.120251     57.92"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, columns=['Train loss', 'Accuracy'],\n",
    "             index=['RNN', 'GRU', 'LSTM', 'LSTM2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем сложнее модель (просто `RNN` -> `GRU` -> `LSTM`), тем лучше получаются результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая по началу высказывания будет генерировать следующие length_to_predict символов.\n",
    "Для этого нужно сначала входной текст привести в формату, который принимает на вход модель. После этого предсказать первый символ. Предсказаный символ следует добавить в конец текста и полученный текст опять привести к нужному формату. После этого можно предсказать следующий символ и так далее.<br>\n",
    "\n",
    "*Замечания* <br>\n",
    "1) Модель принимает объекты батчами, поэтому если вы будете подавать ей один элемент она будет ругаться. Один элемент нужно подавать как батч размера 1. <br>\n",
    "2) Для получения предсказания в виде индекса следующего символа нужно найти аргмаксимум по логитам. В этом вам поможет logits.max(dim), который принимает в аргументах размерность dim по которой искать максимумы и возвращает сразу 2 тензора - максимумы и индексы максимумов.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, length_to_predict):\n",
    "    with torch.no_grad():\n",
    "        input_text = text[-maxlen:]\n",
    "        if len(input_text) < maxlen:\n",
    "            input_text = [PAD] * (maxlen - len(input_text)) + input_text\n",
    "        x = np.array([char_indices[c] for c in input_text])\n",
    "        x = torch.LongTensor(x).to(device).unsqueeze(0)\n",
    "        result = []\n",
    "        for i in range(length_to_predict):\n",
    "            logits = model(x)\n",
    "            next_char = torch.argmax(logits)\n",
    "            result.append(next_char.item())\n",
    "            x = torch.cat([x,\n",
    "                torch.LongTensor([next_char]).unsqueeze(0).to(device)], 1)[:, 1:]\n",
    "        return ''.join([indices_char[i] for i in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что предсказывает модель. Не пугайтесь если будет не много смысла в самих высказываниях, это все-таки char-based модель, однако локальный смысл (связанные 3ки-5ки слов) должен присутствовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_rnn, model_gru, model_lstm, model_lstm2]\n",
    "names_list = ['RNN', 'GRU', 'LSTM', 'LSTM2']\n",
    "test_text = \"be no mistake about it: it was neither more nor less \" + \\\n",
    "        \"than a pig, and she felt that it would be quit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sens]\n",
      "\n",
      "GRU: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e becomes and the struggle in the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same distrust of the same dist]\n",
      "\n",
      "LSTM: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e the sense of the same to say the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength and the strength]\n",
      "\n",
      "LSTM2: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e the strength of the senses of the case soul as a strictly and hence of the same to the same the same that is the destruction of the senses and stand of the same the same the same the same to the real of life and let one so that is the same the same to the same the same to look upon a strictude of the sense of the same the same to the most desires and love and manner and seems to the same the des]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m, name in zip(model_list, names_list):\n",
    "    print(f'{name}: {test_text}[{predict(m, test_text, 400)}]')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что один и тот же кусок текста начинает постоянно повторяться (кроме сгенерированного двухслойной `LSTM`). Чтобы этого избежать, будем брать не максимум логитов, а случайный символ с распределением вероятностей, равным `Softmax(logits)` (тогда символ с максимальной вероятностью всё равно будет выбираться чаще всего, но не постоянно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_randomized(model, text, length_to_predict):\n",
    "    with torch.no_grad():\n",
    "        input_text = text[-maxlen:]\n",
    "        if len(input_text) < maxlen:\n",
    "            input_text = [PAD] * (maxlen - len(input_text)) + input_text\n",
    "        x = np.array([char_indices[c] for c in input_text])\n",
    "        x = torch.LongTensor(x).to(device).unsqueeze(0)\n",
    "        result = []\n",
    "        for i in range(length_to_predict):\n",
    "            logits = model(x)\n",
    "            next_char = np.random.choice(np.arange(len(char_indices)),\n",
    "                                p=F.softmax(logits, -1).cpu().numpy())\n",
    "            result.append(next_char)\n",
    "            x = torch.cat([x,\n",
    "                torch.LongTensor([next_char]).unsqueeze(0).to(device)], 1)[:, 1:]\n",
    "        return ''.join([indices_char[i] for i in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e rimalt, sensitive in his tening a colds ideary i something place antil for all new point,\" priflere supletamy, into the propped of alrict, with that we perto.ted also it of the incrifices wea our volugning the necessity, \"which unspirated also regreing be diskinm man\" of more \"foreing feel be obvereme of the barred with it exuad seeice; and a say: the act: at god, self-revere of through this pre]\n",
      "\n",
      "GRU: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e assumen that say some of us: he one partion of his least recognized and it assumedanted in the instinct can years and develop of functions of the behings the herdory and gask, himself.aly sinces, sake of mankind of all geners and yet the same time it often to men.oned himself no different strangest with them of the overturds for greatories, having a pease.tional wrong in which, from an individua]\n",
      "\n",
      "LSTM: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e fear as error of ricks we see superficial namious: for it.y of mean, type of the sames, we conteculity would not necessary, one has be let attempted that i nettemen.s to duty, back man; and consequences means to cause and europeose, it is invertace of lain-discruspifier, and are you had to be indifferent encondibeless itself has he consequences as free his old falsenolish indeed, goethes it.ic, ]\n",
      "\n",
      "LSTM2: be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[e that he himself)!ance is without these or voitus.anced.ing, for its signs wresenses had whoblemens to chabanatical is of openiest for essigle, who way, the violeto which, contentured, sympathy, with logical is so muser has motle\" and a manaby moral much as bood of unconnumentativity,\" in the sense has been unnequilly and moral unow, and assertionity, virtue, the gradatamous clomly clame, wherea,]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m, name in zip(model_list, names_list):\n",
    "    print(f'{name}: {test_text}[{predict_randomized(m, test_text, 400)}]')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что текст, сгенерированный 2-слойной LSTM от такого метода только пострадал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы обучили модель по maxlen предыдущим символам предсказывать один следующий. Именно поэтому для предсказания нескольких следующих символов мы сначала предсказывали один символ, потом добавляли его к входным данным и уже потом предсказывали следуюший. Получается, что для такого предсказания нам нужно прогнать нейросеть столько раз, сколько символов мы хотим предсказывать.<br>\n",
    "\n",
    "Напишите нейросеть, использующую RNN, которая не будет иметь такой проблемы. Она должна обучиться на *каждом шаге* rnn предсказывать следующее слово. Для этого вам понадобится к каждому скрытому состоянию вашей rnn применить некоторую классификационную нейросеть, аналогичную классификационной нейросети ранее. Каждая такая сеть будет пытаться предсказать следующее слово на своем этапе. На каждом этапе времени вы получите свое предсказание вероятности для следующего символа, после этого усредните лосс по этим предсказаниям. <br>\n",
    "\n",
    "**Замечания** <br>\n",
    "1) Проследите, что вы действительно предсказываете следующий символ, а не текущий. Проще всего поступить так : \n",
    "пусть на вход приходит последовательность $x_1, x_2, ..., x_{maxlen}$ и вы хотите на каждом этапе времени t по символам $x_1, ..., x_{t - 1}$ предсказывать символ $x_t$. Для этого на вход нужно подать последовательность $BOS, x_1, x_2..., x_{maxlen - 1}$ и в качестве таргетов взять последовательность $x_1, x_2, ..., x_{maxlen}$. BOS (begin of sentence) - специальный символ начала предложения (любой новый символ, которого нет в словаре). \n",
    "\n",
    "2) При обучении вы подаете на вход истинные символы и предсказываете следующий, а при тестировании у вас этих истинных символов нет. Поэтому при тестировании вам нужно поступить так :\n",
    "Сначала берем на вход $BOS$, применяем рекуррентную ячейку и предсказываем вероятности быть следующим символом для каждого символа из словаря. Находим символ с максимальной вероятностью, обозначим его $x_1$. Теперь подаем символ $x_1$ на вход рекуррентной ячейке и предсказываем вероятности для следующих символов. Заметим, что если вы имеете некоторые начальные символы $x_1, .., x_k$, которые нужно продолжить, то сначала на вход будут подаваться истинные символы, а потом, когда те закончатся, предсказанные символы.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "На рисунке можно увидеть пример такой сети. При обучении мы подаем на вход истинные символы и на этапе времени $i - 1$ предсказываем вероятности $\\widehat{y^{(i)}}$ быть следующим ($i$ - ым) словом для всех слов из словаря. \n",
    "<br>Лоссом здесь будет $\\frac{1}{maxlen} \\sum\\limits_i^{maxlen} cross\\_entropy(\\widehat{y^{(i)}}, y^{(i)})$, где  $y^{(i)}$  - истинный индекс $i$-ого слова.\n",
    "\n",
    "При тестировании на вход рекуррентной ячейке подается не настоящий символ, а символ, который имел наибольшую вероятность быть следующим на предыдущем шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://i.ibb.co/BnftCLh/Screenshot-2019-05-03-at-21-45-01.png)\n",
    "\n",
    "![imh](https://i.ibb.co/rwHyYsK/Screenshot-2019-05-03-at-21-44-53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения этого задания вам понадобятся `nn.RNNCell`, `nn.LSTMCell` или `nn.GRUCell`. <br>\n",
    "Как с ними работать вы разбирались на семинаре основного курса : https://github.com/ml-mipt/ml-mipt/blob/master/week12_seq2seq_and_embeddings/rnn_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придётся немного поменять предобработку данных: добавить токены начала и конца последовательности + в батч будет попадать только сама последовательность индексов (содержащая в себе и X, и target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 59\n",
      "count of elements in dataset: 25306\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 20\n",
    "PAD = '#'\n",
    "BOS = '[BOS]'\n",
    "EOS = '[EOS]'\n",
    "chars = sorted(list(set(text)) + [PAD, BOS, EOS])\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "current_phrase = ''\n",
    "phrases = []\n",
    "for s in text:\n",
    "    current_phrase += s\n",
    "    if s in ['.', '!', '?']:\n",
    "        if len(current_phrase) != 0:\n",
    "            phrases.append([BOS] + [c for c in current_phrase.strip()] + [EOS])\n",
    "        current_phrase = ''    \n",
    "\n",
    "char_seqs = []\n",
    "for p in phrases:\n",
    "    for i in range(0, len(p) - maxlen, step):\n",
    "        char_seqs.append(p[i:i + maxlen])\n",
    "\n",
    "print('count of elements in dataset:', len(char_seqs))\n",
    "\n",
    "x = np.array([[char_indices[c] for c in p] for p in char_seqs])\n",
    "X_train, X_val = train_test_split(x, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_dim=128,\n",
    "                 out_size=len(chars),\n",
    "                 cell_type=nn.LSTMCell, device='cpu'):\n",
    "        super(CellModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        self.device = device\n",
    "        self.cell_type = cell_type\n",
    "        \n",
    "        self.embeddings = nn.Embedding(self.out_size, self.input_size) \n",
    "        self.rnn_cell = self.cell_type(input_size=self.input_size,\n",
    "                         hidden_size=self.hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, out_size)\n",
    "        \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        x = self.embeddings(x)\n",
    "        hidden_states = []\n",
    "        hc = (h, c)\n",
    "        if h is None or c is None:\n",
    "            hc = None\n",
    "        for i in range(x.shape[1]):\n",
    "            h, c = self.rnn_cell(x[:, i, :], hc)\n",
    "            hc = (h, c)\n",
    "            hidden_states.append(h.unsqueeze(1))\n",
    "        logits = self.fc(torch.cat(hidden_states, 1))\n",
    "        return logits, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_accuracy = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_seq(model, X_batch, pad_ix=char_indices[PAD]):\n",
    "    logits, _, _ = model(X_batch[:, :-1])\n",
    "    return F.cross_entropy(logits.reshape(-1, logits.shape[-1]),\n",
    "                           X_batch[:, 1:].reshape(-1), ignore_index=pad_ix)\n",
    "\n",
    "def iterate_minibatches_seq(X, batch_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        indices = np.arange(len(X))\n",
    "        \n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        ix = indices[start: start + batch_size]\n",
    "        yield torch.LongTensor(X[ix]).to(device)\n",
    "\n",
    "def train_cell(model, num_epochs=10, batch_size=32, lr=1e-4):\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train(True)\n",
    "        for X_batch in iterate_minibatches_seq(X_train, batch_size, True):\n",
    "            loss = compute_loss_seq(model, X_batch, pad_ix=char_indices[PAD])\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        model.train(False)\n",
    "        for X_batch in iterate_minibatches_seq(X_val, batch_size, False):\n",
    "            logits, _, _ = model(X_batch[:, :-1])\n",
    "            loss = F.cross_entropy(logits.reshape(-1, logits.shape[-1]),\n",
    "                                   X_batch[:, 1:].reshape(-1),\n",
    "                                   ignore_index=char_indices[PAD]) \n",
    "            y_pred = logits.max(-1)[1]\n",
    "            val_accuracy.append((X_batch[:, 1:] == y_pred).type(torch.FloatTensor).mean().item())\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))\n",
    "    return model, train_loss, val_accuracy, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 200 took 1.921s\n",
      "  training loss (in-iteration): \t2.924449\n",
      "  validation accuracy: \t\t\t31.35 %\n",
      "Epoch 2 of 200 took 1.929s\n",
      "  training loss (in-iteration): \t2.305787\n",
      "  validation accuracy: \t\t\t36.17 %\n",
      "Epoch 3 of 200 took 1.943s\n",
      "  training loss (in-iteration): \t2.143227\n",
      "  validation accuracy: \t\t\t39.57 %\n",
      "Epoch 4 of 200 took 1.994s\n",
      "  training loss (in-iteration): \t2.037093\n",
      "  validation accuracy: \t\t\t41.85 %\n",
      "Epoch 5 of 200 took 1.988s\n",
      "  training loss (in-iteration): \t1.959373\n",
      "  validation accuracy: \t\t\t43.66 %\n",
      "Epoch 6 of 200 took 1.953s\n",
      "  training loss (in-iteration): \t1.899085\n",
      "  validation accuracy: \t\t\t45.11 %\n",
      "Epoch 7 of 200 took 1.945s\n",
      "  training loss (in-iteration): \t1.849669\n",
      "  validation accuracy: \t\t\t46.21 %\n",
      "Epoch 8 of 200 took 1.984s\n",
      "  training loss (in-iteration): \t1.808286\n",
      "  validation accuracy: \t\t\t47.33 %\n",
      "Epoch 9 of 200 took 2.047s\n",
      "  training loss (in-iteration): \t1.772831\n",
      "  validation accuracy: \t\t\t48.14 %\n",
      "Epoch 10 of 200 took 2.017s\n",
      "  training loss (in-iteration): \t1.742087\n",
      "  validation accuracy: \t\t\t48.74 %\n",
      "Epoch 11 of 200 took 1.964s\n",
      "  training loss (in-iteration): \t1.714974\n",
      "  validation accuracy: \t\t\t49.34 %\n",
      "Epoch 12 of 200 took 1.954s\n",
      "  training loss (in-iteration): \t1.690990\n",
      "  validation accuracy: \t\t\t49.91 %\n",
      "Epoch 13 of 200 took 1.952s\n",
      "  training loss (in-iteration): \t1.669250\n",
      "  validation accuracy: \t\t\t50.36 %\n",
      "Epoch 14 of 200 took 2.008s\n",
      "  training loss (in-iteration): \t1.650004\n",
      "  validation accuracy: \t\t\t50.88 %\n",
      "Epoch 15 of 200 took 2.009s\n",
      "  training loss (in-iteration): \t1.632180\n",
      "  validation accuracy: \t\t\t51.34 %\n",
      "Epoch 16 of 200 took 2.003s\n",
      "  training loss (in-iteration): \t1.615992\n",
      "  validation accuracy: \t\t\t51.82 %\n",
      "Epoch 17 of 200 took 1.957s\n",
      "  training loss (in-iteration): \t1.600990\n",
      "  validation accuracy: \t\t\t52.09 %\n",
      "Epoch 18 of 200 took 2.006s\n",
      "  training loss (in-iteration): \t1.587381\n",
      "  validation accuracy: \t\t\t52.60 %\n",
      "Epoch 19 of 200 took 1.959s\n",
      "  training loss (in-iteration): \t1.574680\n",
      "  validation accuracy: \t\t\t52.90 %\n",
      "Epoch 20 of 200 took 1.924s\n",
      "  training loss (in-iteration): \t1.562987\n",
      "  validation accuracy: \t\t\t53.11 %\n",
      "Epoch 21 of 200 took 1.954s\n",
      "  training loss (in-iteration): \t1.551999\n",
      "  validation accuracy: \t\t\t53.53 %\n",
      "Epoch 22 of 200 took 1.962s\n",
      "  training loss (in-iteration): \t1.541547\n",
      "  validation accuracy: \t\t\t53.70 %\n",
      "Epoch 23 of 200 took 1.990s\n",
      "  training loss (in-iteration): \t1.531514\n",
      "  validation accuracy: \t\t\t53.91 %\n",
      "Epoch 24 of 200 took 1.944s\n",
      "  training loss (in-iteration): \t1.521924\n",
      "  validation accuracy: \t\t\t54.28 %\n",
      "Epoch 25 of 200 took 2.005s\n",
      "  training loss (in-iteration): \t1.512683\n",
      "  validation accuracy: \t\t\t54.58 %\n",
      "Epoch 26 of 200 took 1.974s\n",
      "  training loss (in-iteration): \t1.504295\n",
      "  validation accuracy: \t\t\t54.78 %\n",
      "Epoch 27 of 200 took 1.932s\n",
      "  training loss (in-iteration): \t1.495986\n",
      "  validation accuracy: \t\t\t54.98 %\n",
      "Epoch 28 of 200 took 1.929s\n",
      "  training loss (in-iteration): \t1.488428\n",
      "  validation accuracy: \t\t\t55.02 %\n",
      "Epoch 29 of 200 took 1.957s\n",
      "  training loss (in-iteration): \t1.480930\n",
      "  validation accuracy: \t\t\t55.18 %\n",
      "Epoch 30 of 200 took 1.970s\n",
      "  training loss (in-iteration): \t1.474192\n",
      "  validation accuracy: \t\t\t55.49 %\n",
      "Epoch 31 of 200 took 1.980s\n",
      "  training loss (in-iteration): \t1.467491\n",
      "  validation accuracy: \t\t\t55.66 %\n",
      "Epoch 32 of 200 took 2.006s\n",
      "  training loss (in-iteration): \t1.461081\n",
      "  validation accuracy: \t\t\t55.86 %\n",
      "Epoch 33 of 200 took 1.969s\n",
      "  training loss (in-iteration): \t1.454849\n",
      "  validation accuracy: \t\t\t55.89 %\n",
      "Epoch 34 of 200 took 1.899s\n",
      "  training loss (in-iteration): \t1.449010\n",
      "  validation accuracy: \t\t\t56.06 %\n",
      "Epoch 35 of 200 took 2.016s\n",
      "  training loss (in-iteration): \t1.443199\n",
      "  validation accuracy: \t\t\t56.16 %\n",
      "Epoch 36 of 200 took 1.999s\n",
      "  training loss (in-iteration): \t1.437843\n",
      "  validation accuracy: \t\t\t56.27 %\n",
      "Epoch 37 of 200 took 1.951s\n",
      "  training loss (in-iteration): \t1.432692\n",
      "  validation accuracy: \t\t\t56.39 %\n",
      "Epoch 38 of 200 took 1.945s\n",
      "  training loss (in-iteration): \t1.427636\n",
      "  validation accuracy: \t\t\t56.44 %\n",
      "Epoch 39 of 200 took 1.958s\n",
      "  training loss (in-iteration): \t1.423195\n",
      "  validation accuracy: \t\t\t56.65 %\n",
      "Epoch 40 of 200 took 1.950s\n",
      "  training loss (in-iteration): \t1.418424\n",
      "  validation accuracy: \t\t\t56.69 %\n",
      "Epoch 41 of 200 took 1.966s\n",
      "  training loss (in-iteration): \t1.414131\n",
      "  validation accuracy: \t\t\t56.82 %\n",
      "Epoch 42 of 200 took 1.996s\n",
      "  training loss (in-iteration): \t1.409947\n",
      "  validation accuracy: \t\t\t56.89 %\n",
      "Epoch 43 of 200 took 1.951s\n",
      "  training loss (in-iteration): \t1.405841\n",
      "  validation accuracy: \t\t\t56.90 %\n",
      "Epoch 44 of 200 took 2.002s\n",
      "  training loss (in-iteration): \t1.401887\n",
      "  validation accuracy: \t\t\t57.02 %\n",
      "Epoch 45 of 200 took 1.932s\n",
      "  training loss (in-iteration): \t1.398285\n",
      "  validation accuracy: \t\t\t57.26 %\n",
      "Epoch 46 of 200 took 1.956s\n",
      "  training loss (in-iteration): \t1.394540\n",
      "  validation accuracy: \t\t\t57.20 %\n",
      "Epoch 47 of 200 took 1.936s\n",
      "  training loss (in-iteration): \t1.391203\n",
      "  validation accuracy: \t\t\t57.26 %\n",
      "Epoch 48 of 200 took 1.961s\n",
      "  training loss (in-iteration): \t1.387757\n",
      "  validation accuracy: \t\t\t57.42 %\n",
      "Epoch 49 of 200 took 1.973s\n",
      "  training loss (in-iteration): \t1.384603\n",
      "  validation accuracy: \t\t\t57.52 %\n",
      "Epoch 50 of 200 took 1.998s\n",
      "  training loss (in-iteration): \t1.381404\n",
      "  validation accuracy: \t\t\t57.46 %\n",
      "Epoch 51 of 200 took 1.988s\n",
      "  training loss (in-iteration): \t1.378242\n",
      "  validation accuracy: \t\t\t57.59 %\n",
      "Epoch 52 of 200 took 1.977s\n",
      "  training loss (in-iteration): \t1.375180\n",
      "  validation accuracy: \t\t\t57.64 %\n",
      "Epoch 53 of 200 took 1.932s\n",
      "  training loss (in-iteration): \t1.372498\n",
      "  validation accuracy: \t\t\t57.81 %\n",
      "Epoch 54 of 200 took 1.987s\n",
      "  training loss (in-iteration): \t1.369612\n",
      "  validation accuracy: \t\t\t57.70 %\n",
      "Epoch 55 of 200 took 1.954s\n",
      "  training loss (in-iteration): \t1.366911\n",
      "  validation accuracy: \t\t\t57.93 %\n",
      "Epoch 56 of 200 took 1.991s\n",
      "  training loss (in-iteration): \t1.364038\n",
      "  validation accuracy: \t\t\t57.94 %\n",
      "Epoch 57 of 200 took 2.016s\n",
      "  training loss (in-iteration): \t1.361481\n",
      "  validation accuracy: \t\t\t57.98 %\n",
      "Epoch 58 of 200 took 1.963s\n",
      "  training loss (in-iteration): \t1.359136\n",
      "  validation accuracy: \t\t\t58.13 %\n",
      "Epoch 59 of 200 took 1.956s\n",
      "  training loss (in-iteration): \t1.356585\n",
      "  validation accuracy: \t\t\t58.09 %\n",
      "Epoch 60 of 200 took 1.942s\n",
      "  training loss (in-iteration): \t1.354332\n",
      "  validation accuracy: \t\t\t58.30 %\n",
      "Epoch 61 of 200 took 1.965s\n",
      "  training loss (in-iteration): \t1.351868\n",
      "  validation accuracy: \t\t\t58.18 %\n",
      "Epoch 62 of 200 took 1.897s\n",
      "  training loss (in-iteration): \t1.349850\n",
      "  validation accuracy: \t\t\t58.32 %\n",
      "Epoch 63 of 200 took 1.999s\n",
      "  training loss (in-iteration): \t1.347588\n",
      "  validation accuracy: \t\t\t58.31 %\n",
      "Epoch 64 of 200 took 1.947s\n",
      "  training loss (in-iteration): \t1.345352\n",
      "  validation accuracy: \t\t\t58.34 %\n",
      "Epoch 65 of 200 took 2.334s\n",
      "  training loss (in-iteration): \t1.343176\n",
      "  validation accuracy: \t\t\t58.35 %\n",
      "Epoch 66 of 200 took 2.287s\n",
      "  training loss (in-iteration): \t1.341196\n",
      "  validation accuracy: \t\t\t58.55 %\n",
      "Epoch 67 of 200 took 2.319s\n",
      "  training loss (in-iteration): \t1.339197\n",
      "  validation accuracy: \t\t\t58.53 %\n",
      "Epoch 68 of 200 took 2.347s\n",
      "  training loss (in-iteration): \t1.337168\n",
      "  validation accuracy: \t\t\t58.44 %\n",
      "Epoch 69 of 200 took 2.358s\n",
      "  training loss (in-iteration): \t1.335342\n",
      "  validation accuracy: \t\t\t58.71 %\n",
      "Epoch 70 of 200 took 2.369s\n",
      "  training loss (in-iteration): \t1.333169\n",
      "  validation accuracy: \t\t\t58.65 %\n",
      "Epoch 71 of 200 took 2.226s\n",
      "  training loss (in-iteration): \t1.331667\n",
      "  validation accuracy: \t\t\t58.71 %\n",
      "Epoch 72 of 200 took 2.385s\n",
      "  training loss (in-iteration): \t1.329640\n",
      "  validation accuracy: \t\t\t58.61 %\n",
      "Epoch 73 of 200 took 2.238s\n",
      "  training loss (in-iteration): \t1.328169\n",
      "  validation accuracy: \t\t\t58.75 %\n",
      "Epoch 74 of 200 took 2.376s\n",
      "  training loss (in-iteration): \t1.326214\n",
      "  validation accuracy: \t\t\t58.71 %\n",
      "Epoch 75 of 200 took 2.292s\n",
      "  training loss (in-iteration): \t1.324866\n",
      "  validation accuracy: \t\t\t58.68 %\n",
      "Epoch 76 of 200 took 2.350s\n",
      "  training loss (in-iteration): \t1.322930\n",
      "  validation accuracy: \t\t\t58.84 %\n",
      "Epoch 77 of 200 took 2.320s\n",
      "  training loss (in-iteration): \t1.321433\n",
      "  validation accuracy: \t\t\t58.85 %\n",
      "Epoch 78 of 200 took 2.317s\n",
      "  training loss (in-iteration): \t1.319784\n",
      "  validation accuracy: \t\t\t58.80 %\n",
      "Epoch 79 of 200 took 2.340s\n",
      "  training loss (in-iteration): \t1.318096\n",
      "  validation accuracy: \t\t\t58.96 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 of 200 took 2.333s\n",
      "  training loss (in-iteration): \t1.316548\n",
      "  validation accuracy: \t\t\t58.88 %\n",
      "Epoch 81 of 200 took 2.325s\n",
      "  training loss (in-iteration): \t1.315317\n",
      "  validation accuracy: \t\t\t59.00 %\n",
      "Epoch 82 of 200 took 2.304s\n",
      "  training loss (in-iteration): \t1.313697\n",
      "  validation accuracy: \t\t\t59.01 %\n",
      "Epoch 83 of 200 took 2.261s\n",
      "  training loss (in-iteration): \t1.312354\n",
      "  validation accuracy: \t\t\t59.11 %\n",
      "Epoch 84 of 200 took 2.296s\n",
      "  training loss (in-iteration): \t1.310563\n",
      "  validation accuracy: \t\t\t59.07 %\n",
      "Epoch 85 of 200 took 2.224s\n",
      "  training loss (in-iteration): \t1.309429\n",
      "  validation accuracy: \t\t\t59.03 %\n",
      "Epoch 86 of 200 took 2.338s\n",
      "  training loss (in-iteration): \t1.307895\n",
      "  validation accuracy: \t\t\t59.13 %\n",
      "Epoch 87 of 200 took 2.284s\n",
      "  training loss (in-iteration): \t1.306736\n",
      "  validation accuracy: \t\t\t59.18 %\n",
      "Epoch 88 of 200 took 2.261s\n",
      "  training loss (in-iteration): \t1.305188\n",
      "  validation accuracy: \t\t\t59.11 %\n",
      "Epoch 89 of 200 took 2.356s\n",
      "  training loss (in-iteration): \t1.303983\n",
      "  validation accuracy: \t\t\t59.18 %\n",
      "Epoch 90 of 200 took 2.168s\n",
      "  training loss (in-iteration): \t1.302736\n",
      "  validation accuracy: \t\t\t59.26 %\n",
      "Epoch 91 of 200 took 2.401s\n",
      "  training loss (in-iteration): \t1.301484\n",
      "  validation accuracy: \t\t\t59.18 %\n",
      "Epoch 92 of 200 took 2.233s\n",
      "  training loss (in-iteration): \t1.300436\n",
      "  validation accuracy: \t\t\t59.29 %\n",
      "Epoch 93 of 200 took 2.383s\n",
      "  training loss (in-iteration): \t1.299248\n",
      "  validation accuracy: \t\t\t59.25 %\n",
      "Epoch 94 of 200 took 2.236s\n",
      "  training loss (in-iteration): \t1.298159\n",
      "  validation accuracy: \t\t\t59.28 %\n",
      "Epoch 95 of 200 took 2.403s\n",
      "  training loss (in-iteration): \t1.296772\n",
      "  validation accuracy: \t\t\t59.38 %\n",
      "Epoch 96 of 200 took 2.270s\n",
      "  training loss (in-iteration): \t1.295302\n",
      "  validation accuracy: \t\t\t59.36 %\n",
      "Epoch 97 of 200 took 2.400s\n",
      "  training loss (in-iteration): \t1.294342\n",
      "  validation accuracy: \t\t\t59.44 %\n",
      "Epoch 98 of 200 took 2.291s\n",
      "  training loss (in-iteration): \t1.293434\n",
      "  validation accuracy: \t\t\t59.39 %\n",
      "Epoch 99 of 200 took 2.429s\n",
      "  training loss (in-iteration): \t1.292072\n",
      "  validation accuracy: \t\t\t59.36 %\n",
      "Epoch 100 of 200 took 2.182s\n",
      "  training loss (in-iteration): \t1.290909\n",
      "  validation accuracy: \t\t\t59.53 %\n",
      "Epoch 101 of 200 took 2.398s\n",
      "  training loss (in-iteration): \t1.290074\n",
      "  validation accuracy: \t\t\t59.53 %\n",
      "Epoch 102 of 200 took 2.342s\n",
      "  training loss (in-iteration): \t1.288933\n",
      "  validation accuracy: \t\t\t59.49 %\n",
      "Epoch 103 of 200 took 2.428s\n",
      "  training loss (in-iteration): \t1.287814\n",
      "  validation accuracy: \t\t\t59.56 %\n",
      "Epoch 104 of 200 took 2.258s\n",
      "  training loss (in-iteration): \t1.286921\n",
      "  validation accuracy: \t\t\t59.58 %\n",
      "Epoch 105 of 200 took 2.406s\n",
      "  training loss (in-iteration): \t1.285872\n",
      "  validation accuracy: \t\t\t59.69 %\n",
      "Epoch 106 of 200 took 2.376s\n",
      "  training loss (in-iteration): \t1.284675\n",
      "  validation accuracy: \t\t\t59.60 %\n",
      "Epoch 107 of 200 took 2.339s\n",
      "  training loss (in-iteration): \t1.283884\n",
      "  validation accuracy: \t\t\t59.61 %\n",
      "Epoch 108 of 200 took 2.284s\n",
      "  training loss (in-iteration): \t1.282650\n",
      "  validation accuracy: \t\t\t59.72 %\n",
      "Epoch 109 of 200 took 2.382s\n",
      "  training loss (in-iteration): \t1.281925\n",
      "  validation accuracy: \t\t\t59.59 %\n",
      "Epoch 110 of 200 took 2.263s\n",
      "  training loss (in-iteration): \t1.281230\n",
      "  validation accuracy: \t\t\t59.69 %\n",
      "Epoch 111 of 200 took 2.337s\n",
      "  training loss (in-iteration): \t1.279982\n",
      "  validation accuracy: \t\t\t59.77 %\n",
      "Epoch 112 of 200 took 2.312s\n",
      "  training loss (in-iteration): \t1.279234\n",
      "  validation accuracy: \t\t\t59.63 %\n",
      "Epoch 113 of 200 took 2.331s\n",
      "  training loss (in-iteration): \t1.278289\n",
      "  validation accuracy: \t\t\t59.83 %\n",
      "Epoch 114 of 200 took 2.342s\n",
      "  training loss (in-iteration): \t1.277086\n",
      "  validation accuracy: \t\t\t59.76 %\n",
      "Epoch 115 of 200 took 2.278s\n",
      "  training loss (in-iteration): \t1.276176\n",
      "  validation accuracy: \t\t\t59.66 %\n",
      "Epoch 116 of 200 took 2.345s\n",
      "  training loss (in-iteration): \t1.275468\n",
      "  validation accuracy: \t\t\t59.62 %\n",
      "Epoch 117 of 200 took 2.288s\n",
      "  training loss (in-iteration): \t1.274320\n",
      "  validation accuracy: \t\t\t59.81 %\n",
      "Epoch 118 of 200 took 2.352s\n",
      "  training loss (in-iteration): \t1.273499\n",
      "  validation accuracy: \t\t\t59.82 %\n",
      "Epoch 119 of 200 took 2.291s\n",
      "  training loss (in-iteration): \t1.272789\n",
      "  validation accuracy: \t\t\t59.79 %\n",
      "Epoch 120 of 200 took 2.378s\n",
      "  training loss (in-iteration): \t1.271988\n",
      "  validation accuracy: \t\t\t59.96 %\n",
      "Epoch 121 of 200 took 2.252s\n",
      "  training loss (in-iteration): \t1.271064\n",
      "  validation accuracy: \t\t\t59.88 %\n",
      "Epoch 122 of 200 took 2.346s\n",
      "  training loss (in-iteration): \t1.270221\n",
      "  validation accuracy: \t\t\t59.86 %\n",
      "Epoch 123 of 200 took 2.328s\n",
      "  training loss (in-iteration): \t1.269467\n",
      "  validation accuracy: \t\t\t59.88 %\n",
      "Epoch 124 of 200 took 2.314s\n",
      "  training loss (in-iteration): \t1.268726\n",
      "  validation accuracy: \t\t\t59.98 %\n",
      "Epoch 125 of 200 took 2.390s\n",
      "  training loss (in-iteration): \t1.267451\n",
      "  validation accuracy: \t\t\t59.90 %\n",
      "Epoch 126 of 200 took 2.286s\n",
      "  training loss (in-iteration): \t1.266783\n",
      "  validation accuracy: \t\t\t59.98 %\n",
      "Epoch 127 of 200 took 2.384s\n",
      "  training loss (in-iteration): \t1.265949\n",
      "  validation accuracy: \t\t\t59.87 %\n",
      "Epoch 128 of 200 took 2.289s\n",
      "  training loss (in-iteration): \t1.265357\n",
      "  validation accuracy: \t\t\t60.00 %\n",
      "Epoch 129 of 200 took 2.383s\n",
      "  training loss (in-iteration): \t1.264689\n",
      "  validation accuracy: \t\t\t59.94 %\n",
      "Epoch 130 of 200 took 2.235s\n",
      "  training loss (in-iteration): \t1.263903\n",
      "  validation accuracy: \t\t\t60.04 %\n",
      "Epoch 131 of 200 took 2.376s\n",
      "  training loss (in-iteration): \t1.263205\n",
      "  validation accuracy: \t\t\t59.95 %\n",
      "Epoch 132 of 200 took 2.267s\n",
      "  training loss (in-iteration): \t1.262437\n",
      "  validation accuracy: \t\t\t60.03 %\n",
      "Epoch 133 of 200 took 2.372s\n",
      "  training loss (in-iteration): \t1.261636\n",
      "  validation accuracy: \t\t\t59.97 %\n",
      "Epoch 134 of 200 took 2.306s\n",
      "  training loss (in-iteration): \t1.260749\n",
      "  validation accuracy: \t\t\t60.04 %\n",
      "Epoch 135 of 200 took 2.401s\n",
      "  training loss (in-iteration): \t1.260310\n",
      "  validation accuracy: \t\t\t59.90 %\n",
      "Epoch 136 of 200 took 2.241s\n",
      "  training loss (in-iteration): \t1.259429\n",
      "  validation accuracy: \t\t\t59.97 %\n",
      "Epoch 137 of 200 took 2.396s\n",
      "  training loss (in-iteration): \t1.258692\n",
      "  validation accuracy: \t\t\t59.99 %\n",
      "Epoch 138 of 200 took 2.255s\n",
      "  training loss (in-iteration): \t1.258119\n",
      "  validation accuracy: \t\t\t59.99 %\n",
      "Epoch 139 of 200 took 2.359s\n",
      "  training loss (in-iteration): \t1.257273\n",
      "  validation accuracy: \t\t\t60.09 %\n",
      "Epoch 140 of 200 took 2.346s\n",
      "  training loss (in-iteration): \t1.256663\n",
      "  validation accuracy: \t\t\t60.23 %\n",
      "Epoch 141 of 200 took 2.291s\n",
      "  training loss (in-iteration): \t1.255783\n",
      "  validation accuracy: \t\t\t60.16 %\n",
      "Epoch 142 of 200 took 2.413s\n",
      "  training loss (in-iteration): \t1.255215\n",
      "  validation accuracy: \t\t\t60.10 %\n",
      "Epoch 143 of 200 took 2.264s\n",
      "  training loss (in-iteration): \t1.254433\n",
      "  validation accuracy: \t\t\t60.15 %\n",
      "Epoch 144 of 200 took 2.338s\n",
      "  training loss (in-iteration): \t1.253977\n",
      "  validation accuracy: \t\t\t60.12 %\n",
      "Epoch 145 of 200 took 2.263s\n",
      "  training loss (in-iteration): \t1.253235\n",
      "  validation accuracy: \t\t\t60.06 %\n",
      "Epoch 146 of 200 took 2.434s\n",
      "  training loss (in-iteration): \t1.252666\n",
      "  validation accuracy: \t\t\t60.13 %\n",
      "Epoch 147 of 200 took 2.253s\n",
      "  training loss (in-iteration): \t1.252215\n",
      "  validation accuracy: \t\t\t60.11 %\n",
      "Epoch 148 of 200 took 2.371s\n",
      "  training loss (in-iteration): \t1.251179\n",
      "  validation accuracy: \t\t\t60.11 %\n",
      "Epoch 149 of 200 took 2.335s\n",
      "  training loss (in-iteration): \t1.250705\n",
      "  validation accuracy: \t\t\t60.21 %\n",
      "Epoch 150 of 200 took 2.293s\n",
      "  training loss (in-iteration): \t1.250133\n",
      "  validation accuracy: \t\t\t60.19 %\n",
      "Epoch 151 of 200 took 2.303s\n",
      "  training loss (in-iteration): \t1.249485\n",
      "  validation accuracy: \t\t\t60.21 %\n",
      "Epoch 152 of 200 took 2.331s\n",
      "  training loss (in-iteration): \t1.248961\n",
      "  validation accuracy: \t\t\t60.23 %\n",
      "Epoch 153 of 200 took 2.314s\n",
      "  training loss (in-iteration): \t1.248227\n",
      "  validation accuracy: \t\t\t60.36 %\n",
      "Epoch 154 of 200 took 2.298s\n",
      "  training loss (in-iteration): \t1.247565\n",
      "  validation accuracy: \t\t\t60.24 %\n",
      "Epoch 155 of 200 took 2.376s\n",
      "  training loss (in-iteration): \t1.247008\n",
      "  validation accuracy: \t\t\t60.13 %\n",
      "Epoch 156 of 200 took 2.369s\n",
      "  training loss (in-iteration): \t1.246367\n",
      "  validation accuracy: \t\t\t60.34 %\n",
      "Epoch 157 of 200 took 2.388s\n",
      "  training loss (in-iteration): \t1.245571\n",
      "  validation accuracy: \t\t\t60.25 %\n",
      "Epoch 158 of 200 took 2.266s\n",
      "  training loss (in-iteration): \t1.245085\n",
      "  validation accuracy: \t\t\t60.35 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 of 200 took 2.345s\n",
      "  training loss (in-iteration): \t1.244523\n",
      "  validation accuracy: \t\t\t60.35 %\n",
      "Epoch 160 of 200 took 2.313s\n",
      "  training loss (in-iteration): \t1.244094\n",
      "  validation accuracy: \t\t\t60.25 %\n",
      "Epoch 161 of 200 took 2.326s\n",
      "  training loss (in-iteration): \t1.243372\n",
      "  validation accuracy: \t\t\t60.27 %\n",
      "Epoch 162 of 200 took 2.360s\n",
      "  training loss (in-iteration): \t1.242756\n",
      "  validation accuracy: \t\t\t60.24 %\n",
      "Epoch 163 of 200 took 2.344s\n",
      "  training loss (in-iteration): \t1.242407\n",
      "  validation accuracy: \t\t\t60.27 %\n",
      "Epoch 164 of 200 took 2.306s\n",
      "  training loss (in-iteration): \t1.241580\n",
      "  validation accuracy: \t\t\t60.44 %\n",
      "Epoch 165 of 200 took 2.388s\n",
      "  training loss (in-iteration): \t1.241140\n",
      "  validation accuracy: \t\t\t60.33 %\n",
      "Epoch 166 of 200 took 2.265s\n",
      "  training loss (in-iteration): \t1.240591\n",
      "  validation accuracy: \t\t\t60.40 %\n",
      "Epoch 167 of 200 took 2.374s\n",
      "  training loss (in-iteration): \t1.239977\n",
      "  validation accuracy: \t\t\t60.45 %\n",
      "Epoch 168 of 200 took 2.266s\n",
      "  training loss (in-iteration): \t1.239574\n",
      "  validation accuracy: \t\t\t60.32 %\n",
      "Epoch 169 of 200 took 2.413s\n",
      "  training loss (in-iteration): \t1.239024\n",
      "  validation accuracy: \t\t\t60.40 %\n",
      "Epoch 170 of 200 took 2.215s\n",
      "  training loss (in-iteration): \t1.238461\n",
      "  validation accuracy: \t\t\t60.33 %\n",
      "Epoch 171 of 200 took 2.396s\n",
      "  training loss (in-iteration): \t1.237831\n",
      "  validation accuracy: \t\t\t60.35 %\n",
      "Epoch 172 of 200 took 2.257s\n",
      "  training loss (in-iteration): \t1.237242\n",
      "  validation accuracy: \t\t\t60.36 %\n",
      "Epoch 173 of 200 took 2.367s\n",
      "  training loss (in-iteration): \t1.236836\n",
      "  validation accuracy: \t\t\t60.49 %\n",
      "Epoch 174 of 200 took 2.319s\n",
      "  training loss (in-iteration): \t1.235987\n",
      "  validation accuracy: \t\t\t60.38 %\n",
      "Epoch 175 of 200 took 2.360s\n",
      "  training loss (in-iteration): \t1.235971\n",
      "  validation accuracy: \t\t\t60.48 %\n",
      "Epoch 176 of 200 took 2.306s\n",
      "  training loss (in-iteration): \t1.235348\n",
      "  validation accuracy: \t\t\t60.48 %\n",
      "Epoch 177 of 200 took 2.319s\n",
      "  training loss (in-iteration): \t1.234837\n",
      "  validation accuracy: \t\t\t60.60 %\n",
      "Epoch 178 of 200 took 2.354s\n",
      "  training loss (in-iteration): \t1.234212\n",
      "  validation accuracy: \t\t\t60.36 %\n",
      "Epoch 179 of 200 took 2.360s\n",
      "  training loss (in-iteration): \t1.233705\n",
      "  validation accuracy: \t\t\t60.50 %\n",
      "Epoch 180 of 200 took 2.281s\n",
      "  training loss (in-iteration): \t1.232826\n",
      "  validation accuracy: \t\t\t60.38 %\n",
      "Epoch 181 of 200 took 2.415s\n",
      "  training loss (in-iteration): \t1.232867\n",
      "  validation accuracy: \t\t\t60.34 %\n",
      "Epoch 182 of 200 took 2.301s\n",
      "  training loss (in-iteration): \t1.232195\n",
      "  validation accuracy: \t\t\t60.50 %\n",
      "Epoch 183 of 200 took 2.358s\n",
      "  training loss (in-iteration): \t1.231804\n",
      "  validation accuracy: \t\t\t60.38 %\n",
      "Epoch 184 of 200 took 2.155s\n",
      "  training loss (in-iteration): \t1.231481\n",
      "  validation accuracy: \t\t\t60.31 %\n",
      "Epoch 185 of 200 took 2.373s\n",
      "  training loss (in-iteration): \t1.231006\n",
      "  validation accuracy: \t\t\t60.47 %\n",
      "Epoch 186 of 200 took 2.294s\n",
      "  training loss (in-iteration): \t1.230288\n",
      "  validation accuracy: \t\t\t60.42 %\n",
      "Epoch 187 of 200 took 2.332s\n",
      "  training loss (in-iteration): \t1.229780\n",
      "  validation accuracy: \t\t\t60.47 %\n",
      "Epoch 188 of 200 took 2.300s\n",
      "  training loss (in-iteration): \t1.229376\n",
      "  validation accuracy: \t\t\t60.47 %\n",
      "Epoch 189 of 200 took 2.351s\n",
      "  training loss (in-iteration): \t1.228886\n",
      "  validation accuracy: \t\t\t60.38 %\n",
      "Epoch 190 of 200 took 2.229s\n",
      "  training loss (in-iteration): \t1.228297\n",
      "  validation accuracy: \t\t\t60.55 %\n",
      "Epoch 191 of 200 took 2.256s\n",
      "  training loss (in-iteration): \t1.227880\n",
      "  validation accuracy: \t\t\t60.47 %\n",
      "Epoch 192 of 200 took 2.395s\n",
      "  training loss (in-iteration): \t1.227347\n",
      "  validation accuracy: \t\t\t60.50 %\n",
      "Epoch 193 of 200 took 2.277s\n",
      "  training loss (in-iteration): \t1.226775\n",
      "  validation accuracy: \t\t\t60.54 %\n",
      "Epoch 194 of 200 took 2.351s\n",
      "  training loss (in-iteration): \t1.226497\n",
      "  validation accuracy: \t\t\t60.42 %\n",
      "Epoch 195 of 200 took 2.238s\n",
      "  training loss (in-iteration): \t1.226132\n",
      "  validation accuracy: \t\t\t60.51 %\n",
      "Epoch 196 of 200 took 2.423s\n",
      "  training loss (in-iteration): \t1.225572\n",
      "  validation accuracy: \t\t\t60.47 %\n",
      "Epoch 197 of 200 took 2.257s\n",
      "  training loss (in-iteration): \t1.225632\n",
      "  validation accuracy: \t\t\t60.52 %\n",
      "Epoch 198 of 200 took 2.359s\n",
      "  training loss (in-iteration): \t1.224696\n",
      "  validation accuracy: \t\t\t60.46 %\n",
      "Epoch 199 of 200 took 2.326s\n",
      "  training loss (in-iteration): \t1.224162\n",
      "  validation accuracy: \t\t\t60.53 %\n",
      "Epoch 200 of 200 took 2.285s\n",
      "  training loss (in-iteration): \t1.224228\n",
      "  validation accuracy: \t\t\t60.50 %\n"
     ]
    }
   ],
   "source": [
    "model_cell = CellModel(device=device).to(device)\n",
    "model_cell, train_loss_cell, val_acc_cell, val_loss_cell = train_cell(\n",
    "                            model_cell, num_epochs=200, batch_size=256, lr=5e-4)\n",
    "torch.save(model_cell.state_dict(), 'model_cell')\n",
    "# model_lstm.load_state_dict(torch.load('model_cell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append((1.224228, 60.50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат по accuracy, средний - по лоссу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>1.322897</td>\n",
       "      <td>56.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>1.154201</td>\n",
       "      <td>57.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>1.136434</td>\n",
       "      <td>58.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM2</th>\n",
       "      <td>1.120251</td>\n",
       "      <td>57.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New model</th>\n",
       "      <td>1.224228</td>\n",
       "      <td>60.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train loss  Accuracy\n",
       "RNN          1.322897     56.56\n",
       "GRU          1.154201     57.80\n",
       "LSTM         1.136434     58.02\n",
       "LSTM2        1.120251     57.92\n",
       "New model    1.224228     60.50"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, columns=['Train loss', 'Accuracy'],\n",
    "             index=['RNN', 'GRU', 'LSTM', 'LSTM2', 'New model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишем `predict` с учётом новой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequential_randomized(model, text, length_to_predict):\n",
    "    with torch.no_grad():\n",
    "        x = np.array([char_indices[BOS]]+ [char_indices[c] for c in text])\n",
    "        x = torch.LongTensor(x).to(device).unsqueeze(0)\n",
    "        result = []\n",
    "        hc = None\n",
    "        for i in range(length_to_predict):\n",
    "            logits, h, c = model(x, hc)\n",
    "            hc = (h, c)\n",
    "            logits = logits[:, -1, :].squeeze(0)\n",
    "            next_char = np.random.choice(len(char_indices),\n",
    "                                p=F.softmax(logits, -1).cpu().numpy())\n",
    "            result.append(next_char)\n",
    "            x = torch.LongTensor([next_char]).to(device).unsqueeze(0)\n",
    "        return ''.join([indices_char[i] for i in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quit[s--than only from from us !head! were philosophy) is irronace of them.-to the genius mysting! of results, we fair pro form of the command.er.an), and one still concesural can possible-stryple to be hand when the only equally indiscreed that account, to be devally and before the original pointionem, is tepits to light even up some, has been the same time allows such a consequent, as in order to uta]\n"
     ]
    }
   ],
   "source": [
    "print(f'{test_text}[{predict_sequential_randomized(model_cell, test_text, 400)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
